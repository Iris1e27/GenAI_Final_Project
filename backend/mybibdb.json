{"_default": {"224": {"file": "Kim - 2012 - A User Study Trends in Augmented Reality and Virtu.pdf:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\SU27CUHW\\\\Kim - 2012 - A User Study Trends in Augmented Reality and Virtu.pdf:application/pdf", "pages": "1--5", "year": "2012", "month": "August", "author": "Kim, Si Jung Jun", "publisher": "IEEE", "booktitle": "2012 {International} {Symposium} on {Ubiquitous} {Virtual} {Reality}", "urldate": "2023-10-04", "abstract": "Augmented reality (AR) and virtual reality (VR) are becoming a part of everyday life with the advance of other technologies such as computer vision systems, sensing\ntechnologies, graphics, mobile computing, etc. Their primary goal is to help users achieve their goals effectively and efficiently with satisfaction. This paper describes the trends of how user studies have been incorporated into AR and VR papers published in two major conferences over the past three years. In addition, this paper presents implications on what\nneeds to be taken into account when planning a user study in\nthe field of AR and VR research.", "doi": "10.1109/ISUVR.2012.17", "url": "http://ieeexplore.ieee.org/document/6296796/", "shorttitle": "A {User} {Study} {Trends} in {Augmented} {Reality} and {Virtual} {Reality} {Research}", "isbn": "978-1-4673-2258-4 978-0-7695-4766-4", "title": "A User Study Trends in Augmented Reality and Virtual Reality Research: A Qualitative Study with the Past Three Years of the ISMAR and IEEE VR Conference Papers", "address": "Daejeon, Korea (South)", "ENTRYTYPE": "inproceedings", "ID": "kim_user_2012"}, "225": {"pages": "1--2", "year": "2017", "month": "November", "author": "Mones, Barbara", "publisher": "ACM", "booktitle": "{SIGGRAPH} {Asia} 2017 {Symposium} on {Education}", "urldate": "2023-10-04", "language": "en", "abstract": "The development and potential of Virtual Reality (VR) and Augmented Reality (AR) technologies have already begun to transform classrooms and teaching in ways unimaginable just ten years ago. The increasing integration of these tools and experiences into educational environments has ushered in the possibility of profound changes in the way we think, learn and communicate. Applications for and in education are at the forefront of these changes. AR/VR can enhance the way teachers teach and students learn on all levels from primary school to post graduate education and in all content areas. This new way of experiencing and understanding the world can bring about great opportunities to improve teaching environments and support teachers in their mission to improve the skills and experiences of their students. AR and VR devices now available have made these experiences more affordable, interfaces for uses in education have improved enormously, and people from countries far and wide are able to contribute and connect in ways never available before. When teachers are able to design content that is delivered using AR or VR environments, and students can explore knowledge in a completely different context, opportunities emerge that allow for unique and exciting learning experiments. This panel brings together international experts in industry and education who are making significant contributions to education using these technologies. The panelists will present their newest and ongoing education initiatives, creative and innovative projects, and their plans and predictions for the future. They will discuss the broader ramifications of the dissemination of these new tools.", "doi": "10.1145/3134368.3151011", "url": "https://dl.acm.org/doi/10.1145/3134368.3151011", "shorttitle": "Before and after {AR}/{VR}", "isbn": "978-1-4503-5409-7", "title": "Before and after AR/VR: empowering paradigm shifts in education", "address": "Bangkok Thailand", "ENTRYTYPE": "inproceedings", "ID": "mones_before_2017"}, "226": {"file": "\u5168\u6587:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\4DDRLNFS\\\\Mu\u00f1oz \u7b49 - 2022 - Augmented Reality, Virtual Reality, and Game Techn.pdf:application/pdf", "pages": "222", "year": "2022", "month": "April", "author": "Mu\u00f1oz, Eduardo Gross and Fabregat, Ramon and Bacca-Acosta, Jorge and Duque-M\u00e9ndez, N\u00e9stor and Avila-Garzon, Cecilia", "journal": "Information", "urldate": "2023-10-04", "number": "5", "language": "en", "abstract": "Ophthalmology is a medical profession with a tradition in teaching that has developed throughout history. Although ophthalmologists are generally considered to only prescribe contact lenses, and they handle more than half of eye-related enhancements, diagnoses, and treatments. The training of qualified ophthalmologists is generally carried out under the traditional settings, where there is a supervisor and a student, and training is based on the use of animal eyes or artificial eye models. These models have significant disadvantages, as they are not immersive and are extremely expensive and difficult to acquire. Therefore, technologies related to Augmented Reality (AR) and Virtual Reality (VR) are rapidly and prominently positioning themselves in the medical sector, and the field of ophthalmology is growing exponentially both in terms of the training of professionals and in the assistance and recovery of patients. At the same time, it is necessary to highlight and analyze the developments that have made use of game technologies for the teaching of ophthalmology and the results that have been obtained. This systematic review aims to investigate software and hardware applications developed exclusively for educational environments related to ophthalmology and provide an analysis of other related tools. In addition, the advantages and disadvantages, limitations, and challenges involved in the use of virtual reality, augmented reality, and game technologies in this field are also presented.", "doi": "10.3390/info13050222", "url": "https://www.mdpi.com/2078-2489/13/5/222", "issn": "2078-2489", "volume": "13", "title": "Augmented Reality, Virtual Reality, and Game Technologies in Ophthalmology Training", "ENTRYTYPE": "article", "ID": "munoz_augmented_2022"}, "227": {"file": "\u5168\u6587:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\VXUTEU8D\\\\Xiong \u7b49 - 2021 - Augmented reality and virtual reality displays em.pdf:application/pdf", "pages": "216", "year": "2021", "month": "October", "author": "Xiong, Jianghao and Hsiang, En-Lin and He, Ziqian and Zhan, Tao and Wu, Shin-Tson", "journal": "Light: Science \\& Applications", "urldate": "2023-10-04", "number": "1", "language": "en", "abstract": "Abstract\nWith rapid advances in high-speed communication and computation, augmented reality (AR) and virtual reality (VR) are emerging as next-generation display platforms for deeper human-digital interactions. Nonetheless, to simultaneously match the exceptional performance of human vision and keep the near-eye display module compact and lightweight imposes unprecedented challenges on optical engineering. Fortunately, recent progress in holographic optical elements (HOEs) and lithography-enabled devices provide innovative ways to tackle these obstacles in AR and VR that are otherwise difficult with traditional optics. In this review, we begin with introducing the basic structures of AR and VR headsets, and then describing the operation principles of various HOEs and lithography-enabled devices. Their properties are analyzed in detail, including strong selectivity on wavelength and incident angle, and multiplexing ability of volume HOEs, polarization dependency and active switching of liquid crystal HOEs, device fabrication, and properties of micro-LEDs (light-emitting diodes), and large design freedoms of metasurfaces. Afterwards, we discuss how these devices help enhance the AR and VR performance, with detailed description and analysis of some state-of-the-art architectures. Finally, we cast a perspective on potential developments and research directions of these photonic devices for future AR and VR displays.", "doi": "10.1038/s41377-021-00658-8", "url": "https://www.nature.com/articles/s41377-021-00658-8", "shorttitle": "Augmented reality and virtual reality displays", "issn": "2047-7538", "volume": "10", "title": "Augmented reality and virtual reality displays: emerging technologies and future perspectives", "ENTRYTYPE": "article", "ID": "xiong_augmented_2021"}, "228": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\Q3QULVWU\\\\Kang \u7b49 - 2023 - Large Language Models are Few-shot Testers Explor.pdf:application/pdf", "pages": "2312--2323", "year": "2023", "month": "May", "author": "Kang, Sungmin and Yoon, Juyeon and Yoo, Shin", "publisher": "IEEE", "booktitle": "2023 {IEEE}/{ACM} 45th {International} {Conference} on {Software} {Engineering} ({ICSE})", "urldate": "2023-10-26", "abstract": "Many automated test generation techniques have been developed to aid developers with writing tests. To facilitate full automation, most existing techniques aim to either increase coverage, or generate exploratory inputs. However, existing test generation techniques largely fall short of achieving more semantic objectives, such as generating tests to reproduce a given bug report. Reproducing bugs is nonetheless important, as our empirical study shows that the number of tests added in open source repositories due to issues was about 28\\% of the corresponding project test suite size. Meanwhile, due to the difficulties of transforming the expected program semantics in bug reports into test oracles, existing failure reproduction techniques tend to deal exclusively with program crashes, a small subset of all bug reports. To automate test generation from general bug reports, we propose LIBRO, a framework that uses Large Language Models (LLMs), which have been shown to be capable of performing code-related tasks. Since LLMs themselves cannot execute the target buggy code, we focus on post-processing steps that help us discern when LLMs are effective, and rank the produced tests according to their validity. Our evaluation of LIBRO shows that, on the widely studied Defects4J benchmark, LIBRO can generate failure reproducing test cases for 33\\% of all studied cases (251 out of 750), while suggesting a bug reproducing test in first place for 149 bugs. To mitigate data contamination (i.e., the possibility of the LLM simply remembering the test code either partially or in whole), we also evaluate LIBRO against 31 bug reports submitted after the collection of the LLM training data terminated: LIBRO produces bug reproducing tests for 32\\% of the studied bug reports. Overall, our results show LIBRO has the potential to significantly enhance developer efficiency by automatically generating tests from bug reports.", "doi": "10.1109/ICSE48619.2023.00194", "url": "https://ieeexplore.ieee.org/document/10172763/", "shorttitle": "Large {Language} {Models} are {Few}-shot {Testers}", "isbn": "978-1-66545-701-9", "title": "Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction", "address": "Melbourne, Australia", "ENTRYTYPE": "inproceedings", "ID": "kang_large_2023"}, "229": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\9EUMVTIK\\\\Zheng \u7b49 - 2023 - Judging LLM-as-a-Judge with MT-Bench and Chatbot A.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\5PWUSKWR\\\\2306.html:text/html", "keywords": "Computer Science - Artificial Intelligence, Computer Science - Computation and Language", "note": "arXiv:2306.05685 [cs]", "year": "2023", "month": "October", "author": "Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric P. and Zhang, Hao and Gonzalez, Joseph E. and Stoica, Ion", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm\\_judge.", "url": "http://arxiv.org/abs/2306.05685", "title": "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena", "ENTRYTYPE": "misc", "ID": "zheng_judging_2023"}, "230": {"file": "\u5168\u6587:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\ZXRY9TYM\\\\Zamfirescu-Pereira \u7b49 - 2023 - Why Johnny Can\u2019t Prompt How Non-AI Experts Try (a.pdf:application/pdf", "pages": "1--21", "year": "2023", "month": "April", "author": "Zamfirescu-Pereira, J.D. and Wong, Richmond Y. and Hartmann, Bjoern and Yang, Qian", "publisher": "ACM", "booktitle": "Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Pre-trained large language models (\u201cLLMs\u201d) like GPT-3 can engage in fuent, multi-turn instruction-taking out-of-the-box, making them attractive materials for designing natural language interactions. Using natural language to steer LLM outputs (\u201cprompting\u201d) has emerged as an important design technique potentially accessible to non-AI-experts. Crafting efective prompts can be challenging, however, and prompt-based interactions are brittle. Here, we explore whether non-AI-experts can successfully engage in \u201cend-user prompt engineering\u201d using a design probe\u2014a prototype LLM-based chatbot design tool supporting development and systematic evaluation of prompting strategies. Ultimately, our probe participants explored prompt designs opportunistically, not systematically, and struggled in ways echoing end-user programming systems and interactive machine learning systems. Expectations stemming from human-to-human instructional experiences, and a tendency to overgeneralize, were barriers to efective prompt design. These fndings have implications for non-AI-expert-facing LLM-based tool design and for improving LLM-and-prompt literacy among programmers and the public, and present opportunities for further research.", "doi": "10.1145/3544548.3581388", "url": "https://dl.acm.org/doi/10.1145/3544548.3581388", "shorttitle": "Why {Johnny} {Can}\u2019t {Prompt}", "isbn": "978-1-4503-9421-5", "title": "Why Johnny Can\u2019t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts", "address": "Hamburg Germany", "ENTRYTYPE": "inproceedings", "ID": "zamfirescu-pereira_why_2023"}, "231": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\MMDZAMGG\\\\Liu \u7b49 - 2023 - LLM+P Empowering Large Language Models with Optim.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\A4ACY26B\\\\2304.html:text/html", "keywords": "Computer Science - Artificial Intelligence, Computer Science - Robotics", "note": "arXiv:2304.11477 [cs]", "year": "2023", "month": "September", "author": "Liu, Bo and Jiang, Yuqian and Zhang, Xiaohan and Liu, Qiang and Zhang, Shiqi and Biswas, Joydeep and Stone, Peter", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Large language models (LLMs) have demonstrated remarkable zero-shot generalization abilities: state-of-the-art chatbots can provide plausible answers to many common questions that arise in daily life. However, so far, LLMs cannot reliably solve long-horizon planning problems. By contrast, classical planners, once a problem is given in a formatted way, can use efficient search algorithms to quickly identify correct, or even optimal, plans. In an effort to get the best of both worlds, this paper introduces LLM+P, the first framework that incorporates the strengths of classical planners into LLMs. LLM+P takes in a natural language description of a planning problem, then returns a correct (or optimal) plan for solving that problem in natural language. LLM+P does so by first converting the language description into a file written in the planning domain definition language (PDDL), then leveraging classical planners to quickly find a solution, and then translating the found solution back into natural language. Along with LLM+P, we define a diverse set of different benchmark problems taken from common planning scenarios. Via a comprehensive set of experiments on these benchmark problems, we find that LLM+P is able to provide optimal solutions for most problems, while LLMs fail to provide even feasible plans for most problems.{\\textbackslash}footnote\\{\\vphantom{\\}}The code and results are publicly available at https://github.com/Cranial-XIX/llm-pddl.git.", "url": "http://arxiv.org/abs/2304.11477", "shorttitle": "{LLM}+{P}", "title": "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency", "ENTRYTYPE": "misc", "ID": "liu_llmp_2023"}, "232": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\I4YCHZZE\\\\Penedo \u7b49 - 2023 - The RefinedWeb Dataset for Falcon LLM Outperformi.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\HRS7Y5BL\\\\2306.html:text/html", "keywords": "Computer Science - Artificial Intelligence, Computer Science - Computation and Language", "note": "arXiv:2306.01116 [cs]", "year": "2023", "month": "June", "author": "Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Large language models are commonly trained on a mixture of filtered web data and curated high-quality corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our RefinedWeb dataset, and 1.3/7.5B parameters language models trained on it.", "url": "http://arxiv.org/abs/2306.01116", "shorttitle": "The {RefinedWeb} {Dataset} for {Falcon} {LLM}", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only", "ENTRYTYPE": "misc", "ID": "penedo_refinedweb_2023"}, "233": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\VH69VA8I\\\\Lee \u7b49 - 2022 - CoAuthor Designing a Human-AI Collaborative Writi.pdf:application/pdf", "pages": "1--19", "year": "2022", "month": "April", "author": "Lee, Mina and Liang, Percy and Yang, Qian", "publisher": "ACM", "booktitle": "{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Large language models (LMs) offer unprecedented language generation capabilities and exciting opportunities for interaction design. However, their highly context-dependent capabilities are difficult to grasp and are often subjectively interpreted. In this paper, we argue that by curating and analyzing large interaction datasets, the HCI community can foster more incisive examinations of LMs\u2019 generative capabilities. Exemplifying this approach, we present CoAuthor, a dataset designed for revealing GPT-3\u2019s capabilities in assisting creative and argumentative writing. CoAuthor captures rich interactions between 63 writers and four instances of GPT-3 across 1445 writing sessions. We demonstrate that CoAuthor can address questions about GPT-3\u2019s language, ideation, and collaboration capabilities, and reveal its contribution as a writing \u201ccollaborator\u201d under various definitions of good collaboration. Finally, we discuss how this work may facilitate a more principled discussion around LMs\u2019 promises and pitfalls in relation to interaction design. The dataset and an interface for replaying the writing sessions are publicly available at https://coauthor.stanford.edu.", "doi": "10.1145/3491102.3502030", "url": "https://dl.acm.org/doi/10.1145/3491102.3502030", "shorttitle": "{CoAuthor}", "isbn": "978-1-4503-9157-3", "title": "CoAuthor: Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities", "address": "New Orleans LA USA", "ENTRYTYPE": "inproceedings", "ID": "lee_coauthor_2022"}, "234": {"file": "\u5168\u6587:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\HURRMUAB\\\\Singh \u7b49 - 2023 - Where to Hide a Stolen Elephant Leaps in Creative.pdf:application/pdf", "pages": "1--57", "year": "2023", "month": "October", "author": "Singh, Nikhil and Bernal, Guillermo and Savchenko, Daria and Glassman, Elena L.", "journal": "ACM Transactions on Computer-Human Interaction", "urldate": "2023-10-26", "number": "5", "language": "en", "abstract": "While developing a story, novices and published writers alike have had to look outside themselves for inspiration. Language models have recently been able to generate text fluently, producing new stochastic narratives upon request. However, effectively integrating such capabilities with human cognitive faculties and creative processes remains challenging. We propose to investigate this integration with a multimodal writing support interface that offers writing suggestions textually, visually, and aurally. We conduct an extensive study that combines elicitation of prior expectations before writing, observation and semi-structured interviews during writing, and outcome evaluations after writing. Our results illustrate the individual and situational variation in machine-in-the-loop writing approaches, suggestion acceptance, and ways the system is helpful. Centrally, we report how participants perform\nintegrative leaps\n, by which they do cognitive work to integrate suggestions of varying semantic relevance into their developing stories. We interpret these findings, offering modeling and design recommendations for future creative writing support technologies.", "doi": "10.1145/3511599", "url": "https://dl.acm.org/doi/10.1145/3511599", "shorttitle": "Where to {Hide} a {Stolen} {Elephant}", "issn": "1073-0516, 1557-7325", "volume": "30", "title": "Where to Hide a Stolen Elephant: Leaps in Creative Writing with Multimodal Machine Intelligence", "ENTRYTYPE": "article", "ID": "singh_where_2023"}, "235": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\43U93HNZ\\\\Gero \u7b49 - 2022 - Sparks Inspiration for Science Writing using Lang.pdf:application/pdf", "pages": "1002--1019", "year": "2022", "month": "June", "author": "Gero, Katy Ilonka and Liu, Vivian and Chilton, Lydia", "publisher": "ACM", "booktitle": "Designing {Interactive} {Systems} {Conference}", "urldate": "2023-10-26", "language": "en", "abstract": "Large-scale language models are rapidly improving, performing well on a wide variety of tasks with little to no customization. In this work we investigate how language models can support science writing, a challenging writing task that is both open-ended and highly constrained. We present a system for generating \u201csparks\u201d, sentences related to a scientific concept intended to inspire writers. We find that our sparks are more coherent and diverse than a competitive language model baseline, and approach a human-created gold standard. In a study with 13 PhD students writing on topics of their own selection, we find three main use cases of sparks: aiding with crafting detailed sentences, providing interesting angles to engage readers, and demonstrating common reader perspectives. We also report on the various reasons sparks were considered unhelpful, and discuss how we might improve language models as writing support tools.", "doi": "10.1145/3532106.3533533", "url": "https://dl.acm.org/doi/10.1145/3532106.3533533", "shorttitle": "Sparks", "isbn": "978-1-4503-9358-4", "title": "Sparks: Inspiration for Science Writing using Language Models", "address": "Virtual Event Australia", "ENTRYTYPE": "inproceedings", "ID": "gero_sparks_2022"}, "236": {"pages": "841--852", "year": "2022", "month": "March", "author": "Yuan, Ann and Coenen, Andy and Reif, Emily and Ippolito, Daphne", "publisher": "ACM", "booktitle": "27th {International} {Conference} on {Intelligent} {User} {Interfaces}", "urldate": "2023-10-26", "language": "en", "abstract": "The latest generation of large neural language models such as GPT-3 have achieved new levels of performance on benchmarks for language understanding and generation. These models have even demonstrated an ability to perform arbitrary tasks without explicit training. In this work, we sought to learn how people might use such models in the process of creative writing. We built Wordcraft, a text editor in which users collaborate with a generative language model to write a story. We evaluated Wordcraft with a user study in which participants wrote short stories with and without the tool. Our results show that large language models enable novel co-writing experiences. For example, the language model is able to engage in open-ended conversation about the story, respond to writers\u2019 custom requests expressed in natural language (such as \u201drewrite this text to be more Dickensian\u201d), and generate suggestions that serve to unblock writers in the creative process. Based on these results, we discuss design implications for future human-AI co-writing systems.", "doi": "10.1145/3490099.3511105", "url": "https://dl.acm.org/doi/10.1145/3490099.3511105", "shorttitle": "Wordcraft", "isbn": "978-1-4503-9144-3", "title": "Wordcraft: Story Writing With Large Language Models", "address": "Helsinki Finland", "ENTRYTYPE": "inproceedings", "ID": "yuan_wordcraft_2022"}, "237": {"pages": "1--19", "year": "2022", "month": "April", "author": "Chung, John Joon Young and Kim, Wooseok and Yoo, Kang Min and Lee, Hwaran and Adar, Eytan and Chang, Minsuk", "publisher": "ACM", "booktitle": "{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "While advanced text generation algorithms (e.g., GPT-3) have enabled writers to co-create stories with an AI, guiding the narrative remains a challenge. Existing systems often leverage simple turn-taking between the writer and the AI in story development. However, writers remain unsupported in intuitively understanding the AI\u2019s actions or steering the iterative generation. We introduce TaleBrush, a generative story ideation tool that uses line sketching interactions with a GPT-based language model for control and sensemaking of a protagonist\u2019s fortune in co-created stories. Our empirical evaluation found our pipeline reliably controls story generation while maintaining the novelty of generated sentences. In a user study with 14 participants with diverse writing experiences, we found participants successfully leveraged sketching to iteratively explore and write stories according to their intentions about the character\u2019s fortune while taking inspiration from generated stories. We conclude with a reflection on how sketching interactions can facilitate the iterative human-AI co-creation process.", "doi": "10.1145/3491102.3501819", "url": "https://dl.acm.org/doi/10.1145/3491102.3501819", "shorttitle": "{TaleBrush}", "isbn": "978-1-4503-9157-3", "title": "TaleBrush: Sketching Stories with Generative Pretrained Language Models", "address": "New Orleans LA USA", "ENTRYTYPE": "inproceedings", "ID": "chung_talebrush_2022"}, "238": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\U3XYX34U\\\\Buschek \u7b49 - 2021 - The Impact of Multiple Parallel Phrase Suggestions.pdf:application/pdf", "pages": "1--13", "year": "2021", "month": "May", "author": "Buschek, Daniel and Z\u00fcrn, Martin and Eiband, Malin", "publisher": "ACM", "booktitle": "Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "We present an in-depth analysis of the impact of multi-word suggestion choices from a neural language model on user behaviour regarding input and text composition in email writing. Our study for the first time compares different numbers of parallel suggestions, and use by native and non-native English writers, to explore a trade-off of \u201cefficiency vs ideation\u201d, emerging from recent literature. We built a text editor prototype with a neural language model (GPT-2), refined in a prestudy with 30 people. In an online study (N=156), people composed emails in four conditions (0/1/3/6 parallel suggestions). Our results reveal (1) benefits for ideation, and costs for efficiency, when suggesting multiple phrases; (2) that non-native speakers benefit more from more suggestions; and (3) further insights into behaviour patterns. We discuss implications for research, the design of interactive suggestion systems, and the vision of supporting writers with AI instead of replacing them.", "doi": "10.1145/3411764.3445372", "url": "https://dl.acm.org/doi/10.1145/3411764.3445372", "isbn": "978-1-4503-8096-6", "title": "The Impact of Multiple Parallel Phrase Suggestions on Email Input and Composition Behaviour of Native and Non-Native English Writers", "address": "Yokohama Japan", "ENTRYTYPE": "inproceedings", "ID": "buschek_impact_2021"}, "239": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\L59726KB\\\\Dang \u7b49 - 2022 - Beyond Text Generation Supporting Writers with Co.pdf:application/pdf", "pages": "1--13", "year": "2022", "month": "October", "author": "Dang, Hai and Benharrak, Karim and Lehmann, Florian and Buschek, Daniel", "publisher": "ACM", "booktitle": "Proceedings of the 35th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}", "urldate": "2023-10-26", "language": "en", "abstract": "We propose a text editor to help users plan, structure and reflect on their writing process. It provides continuously updated paragraphwise summaries as margin annotations, using automatic text summarization. Summary levels range from full text, to selected (central) sentences, down to a collection of keywords. To understand how users interact with this system during writing, we conducted two user studies (N=4 and N=8) in which people wrote analytic essays about a given topic and article. As a key finding, the summaries gave users an external perspective on their writing and helped them to revise the content and scope of their drafted paragraphs. People further used the tool to quickly gain an overview of the text and developed strategies to integrate insights from the automated summaries. More broadly, this work explores and highlights the value of designing AI tools for writers, with Natural Language Processing (NLP) capabilities that go beyond direct text generation and correction.", "doi": "10.1145/3526113.3545672", "url": "https://dl.acm.org/doi/10.1145/3526113.3545672", "shorttitle": "Beyond {Text} {Generation}", "isbn": "978-1-4503-9320-1", "title": "Beyond Text Generation: Supporting Writers with Continuous Automatic Text Summaries", "address": "Bend OR USA", "ENTRYTYPE": "inproceedings", "ID": "dang_beyond_2022"}, "240": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\33AJ83GK\\\\Wu \u7b49 - 2022 - AI Chains Transparent and Controllable Human-AI I.pdf:application/pdf", "pages": "1--22", "year": "2022", "month": "April", "author": "Wu, Tongshuang and Terry, Michael and Cai, Carrie Jun", "publisher": "ACM", "booktitle": "{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by \u201cunit-testing\u201d sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications.", "doi": "10.1145/3491102.3517582", "url": "https://dl.acm.org/doi/10.1145/3491102.3517582", "shorttitle": "{AI} {Chains}", "isbn": "978-1-4503-9157-3", "title": "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts", "address": "New Orleans LA USA", "ENTRYTYPE": "inproceedings", "ID": "wu_ai_2022"}, "241": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\KY93ED9R\\\\Goodman \u7b49 - 2022 - LaMPost Design and Evaluation of an AI-assisted E.pdf:application/pdf", "pages": "1--18", "year": "2022", "month": "October", "author": "Goodman, Steven M. and Buehler, Erin and Clary, Patrick and Coenen, Andy and Donsbach, Aaron and Horne, Tiffanie N. and Lahav, Michal and MacDonald, Robert and Michaels, Rain Breaw and Narayanan, Ajit and Pushkarna, Mahima and Riley, Joel and Santana, Alex and Shi, Lei and Sweeney, Rachel and Weaver, Phil and Yuan, Ann and Morris, Meredith Ringel", "publisher": "ACM", "booktitle": "Proceedings of the 24th {International} {ACM} {SIGACCESS} {Conference} on {Computers} and {Accessibility}", "urldate": "2023-10-26", "language": "en", "abstract": "Prior work has explored the writing challenges experienced by people with dyslexia, and the potential for new spelling, grammar, and word retrieval technologies to address these challenges. However, the capabilities for natural language generation demonstrated by the latest class of large language models (LLMs) highlight an opportunity to explore new forms of human-AI writing support tools. In this paper, we introduce LaMPost, a prototype email-writing interface that explores the potential for LLMs to power writing support tools that address the varied needs of people with dyslexia. LaMPost draws from our understanding of these needs and introduces novel AI-powered features for email-writing, including: outlining main ideas, generating a subject line, suggesting changes, rewriting a selection. We evaluated LaMPost with 19 adults with dyslexia, identifying many promising routes for further exploration (including the popularity of the \u201crewrite\u201d and \u201csubject line\u201d features), but also fnding that the current generation of LLMs may not surpass the accuracy and quality thresholds required to meet the needs of writers with dyslexia. Surprisingly, we found that participants\u2019 awareness of the AI had no efect on their perception of the system, nor on their feelings of autonomy, expression, and self-efcacy when writing emails. Our fndings yield further insight into the benefts and drawbacks of using LLMs as writing support for adults with dyslexia and provide a foundation to build upon in future research.", "doi": "10.1145/3517428.3544819", "url": "https://dl.acm.org/doi/10.1145/3517428.3544819", "shorttitle": "{LaMPost}", "isbn": "978-1-4503-9258-7", "title": "LaMPost: Design and Evaluation of an AI-assisted Email Writing Prototype for Adults with Dyslexia", "address": "Athens Greece", "ENTRYTYPE": "inproceedings", "ID": "goodman_lampost_2022"}, "242": {"pages": "1--10", "year": "2021", "month": "May", "author": "Osone, Hiroyuki and Lu, Jun-Li and Ochiai, Yoichi", "publisher": "ACM", "booktitle": "Extended {Abstracts} of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Co-creation with artificial intelligence (AI) is an upcoming trend. However, less attention has been given to the construction of systems for Japanese novelists. In this study, we built \u201cBunCho\u201d, an AI supported story co-creation system in Japanese. BunCho\u2019s AI is GPT-2 (an unsupervised multitask language model) trained using a large-scale dataset of Japanese web texts and novels. With BunCho, users can generate titles and synopses from keywords. Furthermore, we propose an interactive story co-creation AI system as a tabletop role-playing game. According to summative studies of writers (N=16) and readers (N=32), 69\\% writers enjoyed writing synopses with BunCho more than by themselves, and at least one of five common metrics were improved at objective evaluation, including creativity. In addition, 63\\% writers indicated that BunCho broadened their stories. BunCho showed paths to assist Japanese novelists in creating high-level and creative writing.", "doi": "10.1145/3411763.3450391", "url": "https://dl.acm.org/doi/10.1145/3411763.3450391", "shorttitle": "{BunCho}", "isbn": "978-1-4503-8095-9", "title": "BunCho: AI Supported Story Co-Creation via Unsupervised Multitask Learning to Increase Writers\u2019 Creativity in Japanese", "address": "Yokohama Japan", "ENTRYTYPE": "inproceedings", "ID": "osone_buncho_2021"}, "243": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\4KL2K77J\\\\Coenen \u7b49 - 2021 - Wordcraft a Human-AI Collaborative Editor for Sto.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\7F8Q57UI\\\\2107.html:text/html", "keywords": "Computer Science - Computation and Language", "note": "arXiv:2107.07430 [cs]", "year": "2021", "month": "July", "author": "Coenen, Andy and Davis, Luke and Ippolito, Daphne and Reif, Emily and Yuan, Ann", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "As neural language models grow in effectiveness, they are increasingly being applied in real-world settings. However these applications tend to be limited in the modes of interaction they support. In this extended abstract, we propose Wordcraft, an AI-assisted editor for story writing in which a writer and a dialog system collaborate to write a story. Our novel interface uses few-shot learning and the natural affordances of conversation to support a variety of interactions. Our editor provides a sandbox for writers to probe the boundaries of transformer-based language models and paves the way for future human-in-the-loop training pipelines and novel evaluation methods.", "url": "http://arxiv.org/abs/2107.07430", "shorttitle": "Wordcraft", "title": "Wordcraft: a Human-AI Collaborative Editor for Story Writing", "ENTRYTYPE": "misc", "ID": "coenen_wordcraft_2021"}, "244": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\FX3AUXSJ\\\\Liu \u7b49 - 2022 - Opal Multimodal Image Generation for News Illustr.pdf:application/pdf", "pages": "1--17", "year": "2022", "month": "October", "author": "Liu, Vivian and Qiao, Han and Chilton, Lydia", "publisher": "ACM", "booktitle": "Proceedings of the 35th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}", "urldate": "2023-10-26", "language": "en", "abstract": "Advances in multimodal AI have presented people with powerful ways to create images from text. Recent work has shown that textto-image generations are able to represent a broad range of subjects and artistic styles. However, finding the right visual language for text prompts is difficult. In this paper, we address this challenge with Opal, a system that produces text-to-image generations for news illustration. Given an article, Opal guides users through a structured search for visual concepts and provides a pipeline allowing users to generate illustrations based on an article\u2019s tone, keywords, and related artistic styles. Our evaluation shows that Opal efficiently generates diverse sets of news illustrations, visual assets, and concept ideas. Users with Opal generated two times more usable results than users without. We discuss how structured exploration can help users better understand the capabilities of human AI co-creative systems.", "doi": "10.1145/3526113.3545621", "url": "https://dl.acm.org/doi/10.1145/3526113.3545621", "shorttitle": "Opal", "isbn": "978-1-4503-9320-1", "title": "Opal: Multimodal Image Generation for News Illustration", "address": "Bend OR USA", "ENTRYTYPE": "inproceedings", "ID": "liu_opal_2022"}, "245": {"pages": "1--15", "year": "2023", "month": "April", "author": "Gero, Katy Ilonka and Long, Tao and Chilton, Lydia B", "publisher": "ACM", "booktitle": "Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Recently, large language models have made huge advances in generating coherent, creative text. While much research focuses on how users can interact with language models, less work considers the social-technical gap that this technology poses. What are the social nuances that underlie receiving support from a generative AI? In this work we ask when and why a creative writer might turn to a computer versus a peer or mentor for support. We interview 20 creative writers about their writing practice and their attitudes towards both human and computer support. We discover three elements that govern a writer\u2019s interaction with support actors: 1) what writers desire help with, 2) how writers perceive potential support actors, and 3) the values writers hold. We align our results with existing frameworks of writing cognition and creativity support, uncovering the social dynamics which modulate user responses to generative technologies.", "doi": "10.1145/3544548.3580782", "url": "https://dl.acm.org/doi/10.1145/3544548.3580782", "isbn": "978-1-4503-9421-5", "title": "Social Dynamics of AI Support in Creative Writing", "address": "Hamburg Germany", "ENTRYTYPE": "inproceedings", "ID": "gero_social_2023"}, "246": {"pages": "1--16", "year": "2023", "month": "April", "author": "Petridis, Savvas and Diakopoulos, Nicholas and Crowston, Kevin and Hansen, Mark and Henderson, Keren and Jastrzebski, Stan and Nickerson, Jeffrey V and Chilton, Lydia B", "publisher": "ACM", "booktitle": "Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "News media often leverage documents to find ideas for stories, while being critical of the frames and narratives present. Developing angles from a document such as a press release is a cognitively taxing process, in which journalists critically examine the implicit meaning of its claims. Informed by interviews with journalists, we developed AngleKindling, an interactive tool which employs the common sense reasoning of large language models to help journalists explore angles for reporting on a press release. In a study with 12 professional journalists, we show that participants found AngleKindling significantly more helpful and less mentally demanding to use for brainstorming ideas, compared to a prior journalistic angle ideation tool. AngleKindling helped journalists deeply engage with the press release and recognize angles that were useful for multiple types of stories. From our findings, we discuss how to help journalists customize and identify promising angles, and extending AngleKindling to other knowledge-work domains.", "doi": "10.1145/3544548.3580907", "url": "https://dl.acm.org/doi/10.1145/3544548.3580907", "shorttitle": "{AngleKindling}", "isbn": "978-1-4503-9421-5", "title": "AngleKindling: Supporting Journalistic Angle Ideation with Large Language Models", "address": "Hamburg Germany", "ENTRYTYPE": "inproceedings", "ID": "petridis_anglekindling_2023"}, "247": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\7HZ3F46T\\\\Wang \u7b49 - 2023 - PopBlends Strategies for Conceptual Blending with.pdf:application/pdf", "pages": "1--19", "year": "2023", "month": "April", "author": "Wang, Sitong and Petridis, Savvas and Kwon, Taeahn and Ma, Xiaojuan and Chilton, Lydia B", "publisher": "ACM", "booktitle": "Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Pop culture is an important aspect of communication. On social media people often post pop culture reference images that connect an event, product or other entity to a pop culture domain. Creating these images is a creative challenge that requires finding a conceptual connection between the users\u2019 topic and a pop culture domain. In cognitive theory, this task is called conceptual blending. We present a system called PopBlends that automatically suggests conceptual blends. The system explores three approaches that involve both traditional knowledge extraction methods and large language models. Our annotation study shows that all three methods provide connections with similar accuracy, but with very different characteristics. Our user study shows that people found twice as many blend suggestions as they did without the system, and with half the mental demand. We discuss the advantages of combining large language models with knowledge bases for supporting divergent and convergent thinking.", "doi": "10.1145/3544548.3580948", "url": "https://dl.acm.org/doi/10.1145/3544548.3580948", "shorttitle": "{PopBlends}", "isbn": "978-1-4503-9421-5", "title": "PopBlends: Strategies for Conceptual Blending with Large Language Models", "address": "Hamburg Germany", "ENTRYTYPE": "inproceedings", "ID": "wang_popblends_2023"}, "248": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\WH555RBD\\\\Dang \u7b49 - 2023 - Choice Over Control How Users Write with Large La.pdf:application/pdf", "pages": "1--17", "year": "2023", "month": "April", "author": "Dang, Hai and Goller, Sven and Lehmann, Florian and Buschek, Daniel", "publisher": "ACM", "booktitle": "Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "We propose a conceptual perspective on prompts for Large Language Models (LLMs) that distinguishes between (1) diegetic prompts (part of the narrative, e.g. \u201cOnce upon a time, I saw a fox ...\u201d), and (2) non-diegetic prompts (external, e.g. \u201cWrite about the adventures of the fox.\u201d). With this lens, we study how 129 crowd workers on Prolific write short texts with different user interfaces (1 vs 3 suggestions, with/out non-diegetic prompts; implemented with GPT-3): When the interface offered multiple suggestions and provided an option for non-diegetic prompting, participants preferred choosing from multiple suggestions over controlling them via non-diegetic prompts. When participants provided non-diegetic prompts it was to ask for inspiration, topics or facts. Single suggestions in particular were guided both with diegetic and non-diegetic information. This work informs human-AI interaction with generative models by revealing that (1) writing non-diegetic prompts requires effort, (2) people combine diegetic and non-diegetic prompting, and (3) they use their draft (i.e. diegetic information) and suggestion timing to strategically guide LLMs.", "doi": "10.1145/3544548.3580969", "url": "https://dl.acm.org/doi/10.1145/3544548.3580969", "shorttitle": "Choice {Over} {Control}", "isbn": "978-1-4503-9421-5", "title": "Choice Over Control: How Users Write with Large Language Models using Diegetic and Non-Diegetic Prompting", "address": "Hamburg Germany", "ENTRYTYPE": "inproceedings", "ID": "dang_choice_2023"}, "249": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\TYWVVGBY\\\\Long \u7b49 - 2023 - Tweetorial Hooks Generative AI Tools to Motivate .pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\UKG8FYX8\\\\2305.html:text/html", "keywords": "Computer Science - Computers and Society, Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction", "note": "arXiv:2305.12265 [cs]", "year": "2023", "month": "May", "author": "Long, Tao and Zhang, Dorothy and Li, Grace and Taraif, Batool and Menon, Samia and Smith, Kynnedy Simone and Wang, Sitong and Gero, Katy Ilonka and Chilton, Lydia B.", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Communicating science and technology is essential for the public to understand and engage in a rapidly changing world. Tweetorials are an emerging phenomenon where experts explain STEM topics on social media in creative and engaging ways. However, STEM experts struggle to write an engaging \"hook\" in the first tweet that captures the reader's attention. We propose methods to use large language models (LLMs) to help users scaffold their process of writing a relatable hook for complex scientific topics. We demonstrate that LLMs can help writers find everyday experiences that are relatable and interesting to the public, avoid jargon, and spark curiosity. Our evaluation shows that the system reduces cognitive load and helps people write better hooks. Lastly, we discuss the importance of interactivity with LLMs to preserve the correctness, effectiveness, and authenticity of the writing.", "url": "http://arxiv.org/abs/2305.12265", "shorttitle": "Tweetorial {Hooks}", "title": "Tweetorial Hooks: Generative AI Tools to Motivate Science on Social Media", "ENTRYTYPE": "misc", "ID": "long_tweetorial_2023"}, "250": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\5THFZ597\\\\Shen \u7b49 - 2023 - Beyond Summarization Designing AI Support for Rea.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\PCR42KFH\\\\2304.html:text/html", "keywords": "Computer Science - Computation and Language, Computer Science - Human-Computer Interaction", "note": "arXiv:2304.02623 [cs]", "year": "2023", "month": "April", "author": "Shen, Zejiang and August, Tal and Siangliulue, Pao and Lo, Kyle and Bragg, Jonathan and Hammerbacher, Jeff and Downey, Doug and Chang, Joseph Chee and Sontag, David", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Large language models have introduced exciting new opportunities and challenges in designing and developing new AI-assisted writing support tools. Recent work has shown that leveraging this new technology can transform writing in many scenarios such as ideation during creative writing, editing support, and summarization. However, AI-supported expository writing--including real-world tasks like scholars writing literature reviews or doctors writing progress notes--is relatively understudied. In this position paper, we argue that developing AI supports for expository writing has unique and exciting research challenges and can lead to high real-world impacts. We characterize expository writing as evidence-based and knowledge-generating: it contains summaries of external documents as well as new information or knowledge. It can be seen as the product of authors' sensemaking process over a set of source documents, and the interplay between reading, reflection, and writing opens up new opportunities for designing AI support. We sketch three components for AI support design and discuss considerations for future research.", "url": "http://arxiv.org/abs/2304.02623", "shorttitle": "Beyond {Summarization}", "title": "Beyond Summarization: Designing AI Support for Real-World Expository Writing Tasks", "ENTRYTYPE": "misc", "ID": "shen_beyond_2023"}, "251": {"pages": "1--14", "year": "2019", "month": "May", "author": "Chilton, Lydia B. and Petridis, Savvas and Agrawala, Maneesh", "publisher": "ACM", "booktitle": "Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Visual blends are an advanced graphic design technique to draw attention to a message. They combine two objects in a way that is novel and useful in conveying a message symbolically. This paper presents VisiBlends, a flexible workflow for creating visual blends that follows the iterative design process. We introduce a design pattern for blending symbols based on principles of human visual object recognition. Our workflow decomposes the process into both computational techniques and human microtasks. It allows users to collaboratively generate visual blends with steps involving brainstorming, synthesis, and iteration. An evaluation of the workflow shows that decentralized groups can generate blends in independent microtasks, co-located groups can collaboratively make visual blends for their own messages, and VisiBlends improves novices' ability to make visual blends.", "doi": "10.1145/3290605.3300402", "url": "https://dl.acm.org/doi/10.1145/3290605.3300402", "shorttitle": "{VisiBlends}", "isbn": "978-1-4503-5970-2", "title": "VisiBlends: A Flexible Workflow for Visual Blends", "address": "Glasgow Scotland Uk", "ENTRYTYPE": "inproceedings", "ID": "chilton_visiblends_2019"}, "252": {"pages": "1--5", "year": "2021", "month": "May", "author": "Atarashi, Yui", "publisher": "ACM", "booktitle": "Extended {Abstracts} of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "To show off their playing, musicians publish musical performance videos on streaming services. In order to find out typical characteristics of guitar performance videos, we carried out a quantitative survey of guitar performance videos. Then, we discuss key problems of creating effects informed by the survey. According to the discussion, authoring videos with typical effects takes a long time even for experienced users because they typically need to combine multiple video tracks (e.g., lyrics and videos shot from multiple angles) into a single track. They need to synchronize all tracks with the musical piece and set transitions between them at the right timing, aware of the musical structure. This paper presents Instrumeteor, an authoring tool for musical performance videos. First, it automatically analyzes the musical structure in the tracks to align them on a single timeline. Second, it implements typical video effects informed by the survey. In this way, our tool reduces manual work and unleashes the musicians\u2019 creativity.", "doi": "10.1145/3411763.3451521", "url": "https://dl.acm.org/doi/10.1145/3411763.3451521", "shorttitle": "Instrumeteor", "isbn": "978-1-4503-8095-9", "title": "Instrumeteor: Authoring tool for Guitar Performance Video", "address": "Yokohama Japan", "ENTRYTYPE": "inproceedings", "ID": "atarashi_instrumeteor_2021"}, "253": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\S8PXYUUJ\\\\Liu \u7b49 - 2023 - 3DALL-E Integrating Text-to-Image AI in 3D Design.pdf:application/pdf", "pages": "1955--1977", "year": "2023", "month": "July", "author": "Liu, Vivian and Vermeulen, Jo and Fitzmaurice, George and Matejka, Justin", "publisher": "ACM", "booktitle": "Proceedings of the 2023 {ACM} {Designing} {Interactive} {Systems} {Conference}", "urldate": "2023-10-26", "language": "en", "abstract": "Text-to-image AI are capable of generating novel images for inspiration, but their applications for 3D design workflows and how designers can build 3D models using AI-provided inspiration have not yet been explored. To investigate this, we integrated DALL-E, GPT-3, and CLIP within a CAD software in 3DALL-E, a plugin that generates 2D image inspiration for 3D design. 3DALL-E allows users to construct text and image prompts based on what they are modeling. In a study with 13 designers, we found that designers saw great potential in 3DALL-E within their workflows and could use text-to-image AI to produce reference images, prevent design fixation, and inspire design considerations. We elaborate on prompting patterns observed across 3D modeling tasks and provide measures of prompt complexity observed across participants. From our findings, we discuss how 3DALL-E can merge with existing generative design workflows and propose prompt bibliographies as a form of human-AI design history.", "doi": "10.1145/3563657.3596098", "url": "https://dl.acm.org/doi/10.1145/3563657.3596098", "shorttitle": "{3DALL}-{E}", "isbn": "978-1-4503-9893-0", "title": "3DALL-E: Integrating Text-to-Image AI in 3D Design Workflows", "address": "Pittsburgh PA USA", "ENTRYTYPE": "inproceedings", "ID": "liu_3dall-e_2023"}, "254": {"pages": "278--293", "year": "2023", "month": "March", "author": "Hu, Xiaozhu and Huang, Yanwen and Liu, Bo and Wu, Ruolan and Hu, Yongquan and Quigley, Aaron J and Fan, Mingming and Yu, Chun and Shi, Yuanchun", "publisher": "ACM", "booktitle": "Proceedings of the 28th {International} {Conference} on {Intelligent} {User} {Interfaces}", "urldate": "2023-10-26", "language": "en", "abstract": "This work focuses on an active topic in the HCI community, namely tutorial creation by demonstration. We present a novel tool named SmartRecorder that facilitates people, without video editing skills, creating video tutorials for smartphone interaction tasks. As automatic interaction trace extraction is a key component to tutorial generation, we seek to tackle the challenges of automatically extracting user interaction traces on smartphones from screencasts. Uniquely, with respect to prior research in this field, we combine computer vision techniques with IMU-based sensing algorithms, and the technical evaluation results show the importance of smartphone IMU data in improving system performance. With the extracted key information of each step, SmartRecorder generates instructional content initially and provides tutorial creators with a tutorial refinement editor designed based on a high recall (99.38\\%) of key steps to revise the initial instructional content. Finally, SmartRecorder generates video tutorials based on refined instructional content. The results of the user study demonstrate that SmartRecorder allows non-experts to create smartphone usage video tutorials with less time and higher satisfaction from recipients.", "doi": "10.1145/3581641.3584069", "url": "https://dl.acm.org/doi/10.1145/3581641.3584069", "shorttitle": "{SmartRecorder}", "isbn": "9798400701061", "title": "SmartRecorder: An IMU-based Video Tutorial Creation by Demonstration System for Smartphone Interaction Tasks", "address": "Sydney NSW Australia", "ENTRYTYPE": "inproceedings", "ID": "hu_smartrecorder_2023"}, "255": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\RPJ5UP54\\\\Wu \u7b49 - 2022 - AI Chains Transparent and Controllable Human-AI I.pdf:application/pdf", "pages": "1--22", "year": "2022", "month": "April", "author": "Wu, Tongshuang and Terry, Michael and Cai, Carrie Jun", "publisher": "ACM", "booktitle": "{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by \u201cunit-testing\u201d sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications.", "doi": "10.1145/3491102.3517582", "url": "https://dl.acm.org/doi/10.1145/3491102.3517582", "shorttitle": "{AI} {Chains}", "isbn": "978-1-4503-9157-3", "title": "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts", "address": "New Orleans LA USA", "ENTRYTYPE": "inproceedings", "ID": "wu_ai_2022-1"}, "256": {"pages": "623--627", "year": "2022", "month": "June", "author": "Di Fede, Giulia and Rocchesso, Davide and Dow, Steven P. and Andolina, Salvatore", "publisher": "ACM", "booktitle": "Creativity and {Cognition}", "urldate": "2023-10-26", "language": "en", "abstract": "We introduce the Idea Machine, a creativity support tool that leverages large language models (LLMs) to empower people engaged in idea generation tasks. The tool includes a number of affordances that can be used to enable various levels of automation and intelligent support. Each idea entered into the system can be expanded, rewritten, or combined with other ideas or concepts. An idea suggestion mode can also be enabled to make the system proactively suggest ideas.", "doi": "10.1145/3527927.3535197", "url": "https://dl.acm.org/doi/10.1145/3527927.3535197", "shorttitle": "The {Idea} {Machine}", "isbn": "978-1-4503-9327-0", "title": "The Idea Machine: LLM-based Expansion, Rewriting, Combination, and Suggestion of Ideas", "address": "Venice Italy", "ENTRYTYPE": "inproceedings", "ID": "di_fede_idea_2022"}, "257": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\YZD58QMD\\\\Zamfirescu-Pereira \u7b49 - 2023 - Conversation Regression Testing A Design Techniqu.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\4YWDEYZK\\\\2302.html:text/html", "keywords": "Computer Science - Human-Computer Interaction", "note": "arXiv:2302.03154 [cs]", "year": "2023", "month": "February", "author": "Zamfirescu-Pereira, J. D. and Hartmann, Bjoern and Yang, Qian", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Pre-trained language models (LLMs) such as GPT-3 can carry fluent, multi-turn conversations out-of-the-box, making them attractive materials for chatbot design. Further, designers can improve LLM chatbot utterances by prepending textual prompts -- instructions and examples of desired interactions -- to its inputs. However, prompt-based improvements can be brittle; designers face challenges systematically understanding how a prompt strategy might impact the unfolding of subsequent conversations across users. To address this challenge, we introduce the concept of Conversation Regression Testing. Based on sample conversations with a baseline chatbot, Conversation Regression Testing tracks how conversational errors persist or are resolved by applying different prompt strategies. We embody this technique in an interactive design tool, BotDesigner, that lets designers identify archetypal errors across multiple conversations; shows common threads of conversation using a graph visualization; and highlights the effects of prompt changes across bot design iterations. A pilot evaluation demonstrates the usefulness of both the concept of regression testing and the functionalities of BotDesigner for chatbot designers.", "url": "http://arxiv.org/abs/2302.03154", "shorttitle": "Conversation {Regression} {Testing}", "title": "Conversation Regression Testing: A Design Technique for Prototyping Generalizable Prompt Strategies for Pre-trained Language Models", "ENTRYTYPE": "misc", "ID": "zamfirescu-pereira_conversation_2023"}, "258": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\R94HBD7N\\\\Liu \u548c Chilton - 2022 - Design Guidelines for Prompt Engineering Text-to-I.pdf:application/pdf", "pages": "1--23", "year": "2022", "month": "April", "author": "Liu, Vivian and Chilton, Lydia B", "publisher": "ACM", "booktitle": "{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Text-to-image generative models are a new and powerful way to generate visual artwork. However, the open-ended nature of text as interaction is double-edged; while users can input anything and have access to an infinite range of generations, they also must engage in brute-force trial and error with the text prompt when the result quality is poor. We conduct a study exploring what prompt keywords and model hyperparameters can help produce coherent outputs. In particular, we study prompts structured to include subject and style keywords and investigate success and failure modes of these prompts. Our evaluation of 5493 generations over the course of five experiments spans 51 abstract and concrete subjects as well as 51 abstract and figurative styles. From this evaluation, we present design guidelines that can help people produce better outcomes from text-to-image generative models.", "doi": "10.1145/3491102.3501825", "url": "https://dl.acm.org/doi/10.1145/3491102.3501825", "isbn": "978-1-4503-9157-3", "title": "Design Guidelines for Prompt Engineering Text-to-Image Generative Models", "address": "New Orleans LA USA", "ENTRYTYPE": "inproceedings", "ID": "liu_design_2022"}, "259": {"keywords": "Computer Science - Computation and Language, Computer Science - Human-Computer Interaction", "note": "arXiv:2303.03283 [cs]", "year": "2023", "month": "March", "author": "Draxler, Fiona and Werner, Anna and Lehmann, Florian and Hoppe, Matthias and Schmidt, Albrecht and Buschek, Daniel and Welsch, Robin", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Human-AI interaction in text production increases complexity in authorship. In two empirical studies (n1 = 30 \\& n2 = 96), we investigate authorship and ownership in human-AI collaboration for personalized language generation models. We show an AI Ghostwriter Effect: Users do not consider themselves the owners and authors of AI-generated text but refrain from publicly declaring AI authorship. The degree of personalization did not impact the AI Ghostwriter Effect, and control over the model increased participants' sense of ownership. We also found that the discrepancy between the sense of ownership and the authorship declaration is stronger in interactions with a human ghostwriter and that people use similar rationalizations for authorship in AI ghostwriters and human ghostwriters. We discuss how our findings relate to psychological ownership and human-AI interaction to lay the foundations for adapting authorship frameworks and user interfaces in AI in text-generation tasks.", "url": "http://arxiv.org/abs/2303.03283", "shorttitle": "The {AI} {Ghostwriter} {Effect}", "title": "The AI Ghostwriter Effect: Users Do Not Perceive Ownership of AI-Generated Text But Self-Declare as Authors", "ENTRYTYPE": "misc", "ID": "draxler_ai_2023"}, "260": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\WVE859LQ\\\\Zeng \u7b49 - 2023 - AgentTuning Enabling Generalized Agent Abilities .pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\NE6ZG26B\\\\2310.html:text/html", "annote": "Comment: 31 pages", "keywords": "Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning", "note": "arXiv:2310.12823 [cs]", "year": "2023", "month": "October", "author": "Zeng, Aohan and Liu, Mingdao and Lu, Rui and Wang, Bowen and Liu, Xiao and Dong, Yuxiao and Tang, Jie", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Open large language models (LLMs) with great performance in various tasks have significantly advanced the development of LLMs. However, they are far inferior to commercial models such as ChatGPT and GPT-4 when acting as agents to tackle complex tasks in the real world. These agent tasks employ LLMs as the central controller responsible for planning, memorization, and tool utilization, necessitating both fine-grained prompting methods and robust LLMs to achieve satisfactory performance. Though many prompting methods have been proposed to complete particular agent tasks, there is lack of research focusing on improving the agent capabilities of LLMs themselves without compromising their general abilities. In this work, we present AgentTuning, a simple and general method to enhance the agent abilities of LLMs while maintaining their general LLM capabilities. We construct AgentInstruct, a lightweight instruction-tuning dataset containing high-quality interaction trajectories. We employ a hybrid instruction-tuning strategy by combining AgentInstruct with open-source instructions from general domains. AgentTuning is used to instruction-tune the Llama 2 series, resulting in AgentLM. Our evaluations show that AgentTuning enables LLMs' agent capabilities without compromising general abilities. The AgentLM-70B is comparable to GPT-3.5-turbo on unseen agent tasks, demonstrating generalized agent capabilities. We open source the AgentInstruct and AgentLM-7B, 13B, and 70B models at https://github.com/THUDM/AgentTuning, serving open and powerful alternatives to commercial LLMs for agent tasks.", "url": "http://arxiv.org/abs/2310.12823", "shorttitle": "{AgentTuning}", "title": "AgentTuning: Enabling Generalized Agent Abilities for LLMs", "ENTRYTYPE": "misc", "ID": "zeng_agenttuning_2023"}, "261": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\23QCPJGZ\\\\Hong \u7b49 - 2023 - MetaGPT Meta Programming for Multi-Agent Collabor.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\XKBL2ZS7\\\\2308.html:text/html", "keywords": "Computer Science - Artificial Intelligence, Computer Science - Multiagent Systems", "note": "arXiv:2308.00352 [cs]", "year": "2023", "month": "August", "author": "Hong, Sirui and Zheng, Xiawu and Chen, Jonathan and Cheng, Yuheng and Wang, Jinlin and Zhang, Ceyao and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and Zhou, Liyang and Ran, Chenyu and Xiao, Lingfeng and Wu, Chenglin", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Recently, remarkable progress has been made in automated task-solving through the use of multi-agent driven by large language models (LLMs). However, existing LLM-based multi-agent works primarily focus on solving simple dialogue tasks, and complex tasks are rarely studied, mainly due to the LLM hallucination problem. This type of hallucination becomes cascading when naively chaining multiple intelligent agents, resulting in a failure to effectively address complex problems. Therefore, we introduce MetaGPT, an innovative framework that incorporates efficient human workflows as a meta programming approach into LLM-based multi-agent collaboration. Specifically, MetaGPT encodes Standardized Operating Procedures (SOPs) into prompts to enhance structured coordination. Subsequently, it mandates modular outputs, empowering agents with domain expertise comparable to human professionals, to validate outputs and minimize compounded errors. In this way, MetaGPT leverages the assembly line paradigm to assign diverse roles to various agents, thereby establishing a framework that can effectively and cohesively deconstruct complex multi-agent collaborative problems. Our experiments on collaborative software engineering benchmarks demonstrate that MetaGPT generates more coherent and correct solutions compared to existing chat-based multi-agent systems. This highlights the potential of integrating human domain knowledge into multi-agent systems, thereby creating new opportunities to tackle complex real-world challenges. The GitHub repository of this project is publicly available on:https://github.com/geekan/MetaGPT.", "url": "http://arxiv.org/abs/2308.00352", "shorttitle": "{MetaGPT}", "title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework", "ENTRYTYPE": "misc", "ID": "hong_metagpt_2023"}, "262": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\PD7NG9M9\\\\Wu \u7b49 - 2022 - PromptChainer Chaining Large Language Model Promp.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\26RPNDB8\\\\2203.html:text/html", "annote": "Comment: CHI LBW 2022", "keywords": "Computer Science - Human-Computer Interaction", "note": "arXiv:2203.06566 [cs]", "year": "2022", "month": "March", "author": "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J.", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "While LLMs can effectively help prototype single ML functionalities, many real-world applications involve complex tasks that cannot be easily handled via a single run of an LLM. Recent work has found that chaining multiple LLM runs together (with the output of one step being the input to the next) can help users accomplish these more complex tasks, and in a way that is perceived to be more transparent and controllable. However, it remains unknown what users need when authoring their own LLM chains -- a key step for lowering the barriers for non-AI-experts to prototype AI-infused applications. In this work, we explore the LLM chain authoring process. We conclude from pilot studies find that chaining requires careful scaffolding for transforming intermediate node outputs, as well as debugging the chain at multiple granularities; to help with these needs, we designed PromptChainer, an interactive interface for visually programming chains. Through case studies with four people, we show that PromptChainer supports building prototypes for a range of applications, and conclude with open questions on scaling chains to complex tasks, and supporting low-fi chain prototyping.", "url": "http://arxiv.org/abs/2203.06566", "shorttitle": "{PromptChainer}", "title": "PromptChainer: Chaining Large Language Model Prompts through Visual Programming", "ENTRYTYPE": "misc", "ID": "wu_promptchainer_2022"}, "263": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\YMEYJCL3\\\\Sachdeva \u548c McAuley - 2023 - Data Distillation A Survey.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\GDYT9REA\\\\2301.html:text/html", "annote": "Comment: Accepted at TMLR '23. 21 pages, 4 figures", "keywords": "Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Information Retrieval", "note": "arXiv:2301.04272 [cs]", "year": "2023", "month": "September", "author": "Sachdeva, Noveen and McAuley, Julian", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "The popularity of deep learning has led to the curation of a vast number of massive and multifarious datasets. Despite having close-to-human performance on individual tasks, training parameter-hungry models on large datasets poses multi-faceted problems such as (a) high model-training time; (b) slow research iteration; and (c) poor eco-sustainability. As an alternative, data distillation approaches aim to synthesize terse data summaries, which can serve as effective drop-in replacements of the original dataset for scenarios like model training, inference, architecture search, etc. In this survey, we present a formal framework for data distillation, along with providing a detailed taxonomy of existing approaches. Additionally, we cover data distillation approaches for different data modalities, namely images, graphs, and user-item interactions (recommender systems), while also identifying current challenges and future research directions.", "url": "http://arxiv.org/abs/2301.04272", "shorttitle": "Data {Distillation}", "title": "Data Distillation: A Survey", "ENTRYTYPE": "misc", "ID": "sachdeva_data_2023"}, "264": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\KNJ2NF5G\\\\Lin \u7b49 - 2022 - ZIN When and How to Learn Invariance Without Envi.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\77U6KCUK\\\\2203.html:text/html", "annote": "Comment: Accepted by NeurIPS 2022", "keywords": "Computer Science - Artificial Intelligence, Computer Science - Machine Learning", "note": "arXiv:2203.05818 [cs]", "year": "2022", "month": "October", "author": "Lin, Yong and Zhu, Shengyu and Tan, Lu and Cui, Peng", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "It is commonplace to encounter heterogeneous data, of which some aspects of the data distribution may vary but the underlying causal mechanisms remain constant. When data are divided into distinct environments according to the heterogeneity, recent invariant learning methods have proposed to learn robust and invariant models based on this environment partition. It is hence tempting to utilize the inherent heterogeneity even when environment partition is not provided. Unfortunately, in this work, we show that learning invariant features under this circumstance is fundamentally impossible without further inductive biases or additional information. Then, we propose a framework to jointly learn environment partition and invariant representation, assisted by additional auxiliary information. We derive sufficient and necessary conditions for our framework to provably identify invariant features under a fairly general setting. Experimental results on both synthetic and real world datasets validate our analysis and demonstrate an improved performance of the proposed framework over existing methods. Finally, our results also raise the need of making the role of inductive biases more explicit in future works, when considering learning invariant models without environment partition. Codes are available at https://github.com/linyongver/ZIN\\_official .", "url": "http://arxiv.org/abs/2203.05818", "shorttitle": "{ZIN}", "title": "ZIN: When and How to Learn Invariance Without Environment Partition?", "ENTRYTYPE": "misc", "ID": "lin_zin_2022"}, "265": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\KB5LQK9Z\\\\Sun \u7b49 - 2023 - 3D-GPT Procedural 3D Modeling with Large Language.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\8DX5DZR5\\\\2310.html:text/html", "annote": "Comment: Project page: https://chuny1.github.io/3DGPT/3dgpt.html", "keywords": "Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics", "note": "arXiv:2310.12945 [cs]", "year": "2023", "month": "October", "author": "Sun, Chunyi and Han, Junlin and Deng, Weijian and Wang, Xinlong and Qin, Zishan and Gould, Stephen", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "In the pursuit of efficient automated content creation, procedural generation, leveraging modifiable parameters and rule-based systems, emerges as a promising approach. Nonetheless, it could be a demanding endeavor, given its intricate nature necessitating a deep understanding of rules, algorithms, and parameters. To reduce workload, we introduce 3D-GPT, a framework utilizing large language models{\\textasciitilde}(LLMs) for instruction-driven 3D modeling. 3D-GPT positions LLMs as proficient problem solvers, dissecting the procedural 3D modeling tasks into accessible segments and appointing the apt agent for each task. 3D-GPT integrates three core agents: the task dispatch agent, the conceptualization agent, and the modeling agent. They collaboratively achieve two objectives. First, it enhances concise initial scene descriptions, evolving them into detailed forms while dynamically adapting the text based on subsequent instructions. Second, it integrates procedural generation, extracting parameter values from enriched text to effortlessly interface with 3D software for asset creation. Our empirical investigations confirm that 3D-GPT not only interprets and executes instructions, delivering reliable results but also collaborates effectively with human designers. Furthermore, it seamlessly integrates with Blender, unlocking expanded manipulation possibilities. Our work highlights the potential of LLMs in 3D modeling, offering a basic framework for future advancements in scene generation and animation.", "url": "http://arxiv.org/abs/2310.12945", "shorttitle": "{3D}-{GPT}", "title": "3D-GPT: Procedural 3D Modeling with Large Language Models", "ENTRYTYPE": "misc", "ID": "sun_3d-gpt_2023"}, "266": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\BPRU6IAA\\\\Sun \u7b49 - 2023 - SALMON Self-Alignment with Principle-Following Re.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\E3NMH79V\\\\2310.html:text/html", "annote": "Comment: Project page: https://github.com/IBM/SALMON", "keywords": "Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning", "note": "arXiv:2310.05910 [cs]", "year": "2023", "month": "October", "author": "Sun, Zhiqing and Shen, Yikang and Zhang, Hongxin and Zhou, Qinhong and Chen, Zhenfang and Cox, David and Yang, Yiming and Gan, Chuang", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Supervised Fine-Tuning (SFT) on response demonstrations combined with Reinforcement Learning from Human Feedback (RLHF) constitutes a powerful paradigm for aligning LLM-based AI agents. However, a significant limitation of such an approach is its dependency on high-quality human annotations, making its application to intricate tasks challenging due to difficulties in obtaining consistent response demonstrations and in-distribution response preferences. This paper presents a novel approach, namely SALMON (Self-ALignMent with principle-fOllowiNg reward models), to align base language models with minimal human supervision, using only a small set of human-defined principles, yet achieving superior performance. Central to our approach is a principle-following reward model. Trained on synthetic preference data, this model can generate reward scores based on arbitrary human-defined principles. By merely adjusting these principles during the RL training phase, we gain full control over the preferences with the reward model, subsequently influencing the behavior of the RL-trained policies, and eliminating the reliance on the collection of online human preferences. Applying our method to the LLaMA-2-70b base language model, we developed an AI assistant named Dromedary-2. With only 6 exemplars for in-context learning and 31 human-defined principles, Dromedary-2 significantly surpasses the performance of several state-of-the-art AI systems, including LLaMA-2-Chat-70b, on various benchmark datasets. We have open-sourced the code and model weights to encourage further research into aligning LLM-based AI agents with enhanced supervision efficiency, improved controllability, and scalable oversight.", "url": "http://arxiv.org/abs/2310.05910", "shorttitle": "{SALMON}", "title": "SALMON: Self-Alignment with Principle-Following Reward Models", "ENTRYTYPE": "misc", "ID": "sun_salmon_2023"}, "267": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\7RDJEBIS\\\\Liu \u7b49 - 2023 - HallusionBench You See What You Think Or You Thi.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\DTJH6PZ3\\\\2310.html:text/html", "keywords": "Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition", "note": "arXiv:2310.14566 [cs]", "year": "2023", "month": "October", "author": "Liu, Fuxiao and Guan, Tianrui and Li, Zongxia and Chen, Lichang and Yacoob, Yaser and Manocha, Dinesh and Zhou, Tianyi", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Large language models (LLMs), after being aligned with vision models and integrated into vision-language models (VLMs), can bring impressive improvement in image reasoning tasks. This was shown by the recently released GPT-4V(ison), LLaVA-1.5, etc. However, the strong language prior in these SOTA LVLMs can be a double-edged sword: they may ignore the image context and solely rely on the (even contradictory) language prior for reasoning. In contrast, the vision modules in VLMs are weaker than LLMs and may result in misleading visual representations, which are then translated to confident mistakes by LLMs. To study these two types of VLM mistakes, i.e., language hallucination and visual illusion, we curated HallusionBench, an image-context reasoning benchmark that is still challenging to even GPT-4V and LLaVA-1.5. We provide a detailed analysis of examples in HallusionBench, which sheds novel insights on the illusion or hallucination of VLMs and how to improve them in the future. The benchmark and codebase will be released at https://github.com/tianyi-lab/HallusionBench.", "url": "http://arxiv.org/abs/2310.14566", "shorttitle": "{HallusionBench}", "title": "HallusionBench: You See What You Think? Or You Think What You See? An Image-Context Reasoning Benchmark Challenging for GPT-4V(ision), LLaVA-1.5, and Other Multi-modality Models", "ENTRYTYPE": "misc", "ID": "liu_hallusionbench_2023"}, "268": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\ABQT6ZXB\\\\Stechly \u7b49 - 2023 - GPT-4 Doesn't Know It's Wrong An Analysis of Iter.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\Q6QPZ7P5\\\\2310.html:text/html", "annote": "Comment: 18 pages, 3 figures", "keywords": "Computer Science - Artificial Intelligence", "note": "arXiv:2310.12397 [cs]", "year": "2023", "month": "October", "author": "Stechly, Kaya and Marquez, Matthew and Kambhampati, Subbarao", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "There has been considerable divergence of opinion on the reasoning abilities of Large Language Models (LLMs). While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples, a wide spread belief in their iterative self-critique capabilities persists. In this paper, we set out to systematically investigate the effectiveness of iterative prompting of LLMs in the context of Graph Coloring, a canonical NP-complete reasoning problem that is related to propositional satisfiability as well as practical problems like scheduling and allocation. We present a principled empirical study of the performance of GPT4 in solving graph coloring instances or verifying the correctness of candidate colorings. In iterative modes, we experiment with the model critiquing its own answers and an external correct reasoner verifying proposed solutions. In both cases, we analyze whether the content of the criticisms actually affects bottom line performance. The study seems to indicate that (i) LLMs are bad at solving graph coloring instances (ii) they are no better at verifying a solution--and thus are not effective in iterative modes with LLMs critiquing LLM-generated solutions (iii) the correctness and content of the criticisms--whether by LLMs or external solvers--seems largely irrelevant to the performance of iterative prompting. We show that the observed increase in effectiveness is largely due to the correct solution being fortuitously present in the top-k completions of the prompt (and being recognized as such by an external verifier). Our results thus call into question claims about the self-critiquing capabilities of state of the art LLMs.", "url": "http://arxiv.org/abs/2310.12397", "shorttitle": "{GPT}-4 {Doesn}'t {Know} {It}'s {Wrong}", "title": "GPT-4 Doesn't Know It's Wrong: An Analysis of Iterative Prompting for Reasoning Problems", "ENTRYTYPE": "misc", "ID": "stechly_gpt-4_2023"}, "269": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\FDHAU9GK\\\\Valmeekam \u7b49 - 2023 - Can Large Language Models Really Improve by Self-c.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\N6XZ7XEE\\\\2310.html:text/html", "keywords": "Computer Science - Artificial Intelligence", "note": "arXiv:2310.08118 [cs]", "year": "2023", "month": "October", "author": "Valmeekam, Karthik and Marquez, Matthew and Kambhampati, Subbarao", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "There have been widespread claims about Large Language Models (LLMs) being able to successfully verify or self-critique their candidate solutions in reasoning problems in an iterative mode. Intrigued by those claims, in this paper we set out to investigate the verification/self-critiquing abilities of large language models in the context of planning. We evaluate a planning system that employs LLMs for both plan generation and verification. We assess the verifier LLM's performance against ground-truth verification, the impact of self-critiquing on plan generation, and the influence of varying feedback levels on system performance. Using GPT-4, a state-of-the-art LLM, for both generation and verification, our findings reveal that self-critiquing appears to diminish plan generation performance, especially when compared to systems with external, sound verifiers and the LLM verifiers in that system produce a notable number of false positives, compromising the system's reliability. Additionally, the nature of feedback, whether binary or detailed, showed minimal impact on plan generation. Collectively, our results cast doubt on the effectiveness of LLMs in a self-critiquing, iterative framework for planning tasks.", "url": "http://arxiv.org/abs/2310.08118", "title": "Can Large Language Models Really Improve by Self-critiquing Their Own Plans?", "ENTRYTYPE": "misc", "ID": "valmeekam_can_2023"}, "270": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\URV56SWR\\\\Xie \u7b49 - 2023 - OpenAgents An Open Platform for Language Agents i.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\LT93LRDL\\\\2310.html:text/html", "annote": "Comment: 34 pages, 8 figures", "keywords": "Computer Science - Artificial Intelligence, Computer Science - Computation and Language", "note": "arXiv:2310.10634 [cs]", "year": "2023", "month": "October", "author": "Xie, Tianbao and Zhou, Fan and Cheng, Zhoujun and Shi, Peng and Weng, Luoxuan and Liu, Yitao and Hua, Toh Jing and Zhao, Junning and Liu, Qian and Liu, Che and Liu, Leo Z. and Xu, Yiheng and Su, Hongjin and Shin, Dongchan and Xiong, Caiming and Yu, Tao", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Language agents show potential in being capable of utilizing natural language for varied and intricate tasks in diverse environments, particularly when built upon large language models (LLMs). Current language agent frameworks aim to facilitate the construction of proof-of-concept language agents while neglecting the non-expert user access to agents and paying little attention to application-level designs. We present OpenAgents, an open platform for using and hosting language agents in the wild of everyday life. OpenAgents includes three agents: (1) Data Agent for data analysis with Python/SQL and data tools; (2) Plugins Agent with 200+ daily API tools; (3) Web Agent for autonomous web browsing. OpenAgents enables general users to interact with agent functionalities through a web user interface optimized for swift responses and common failures while offering developers and researchers a seamless deployment experience on local setups, providing a foundation for crafting innovative language agents and facilitating real-world evaluations. We elucidate the challenges and opportunities, aspiring to set a foundation for future research and development of real-world language agents.", "url": "http://arxiv.org/abs/2310.10634", "shorttitle": "{OpenAgents}", "title": "OpenAgents: An Open Platform for Language Agents in the Wild", "ENTRYTYPE": "misc", "ID": "xie_openagents_2023"}, "271": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\EEX22SUB\\\\Chen \u7b49 - 2023 - MiniGPT-v2 large language model as a unified inte.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\Jingtian Zhang\\\\Zotero\\\\storage\\\\TXN68TQM\\\\2310.html:text/html", "keywords": "Computer Science - Computer Vision and Pattern Recognition", "note": "arXiv:2310.09478 [cs]", "year": "2023", "month": "October", "author": "Chen, Jun and Zhu, Deyao and Shen, Xiaoqian and Li, Xiang and Liu, Zechun and Zhang, Pengchuan and Krishnamoorthi, Raghuraman and Chandra, Vikas and Xiong, Yunyang and Elhoseiny, Mohamed", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Large language models have shown their remarkable capabilities as a general interface for various language-related applications. Motivated by this, we target to build a unified interface for completing many vision-language tasks including image description, visual question answering, and visual grounding, among others. The challenge is to use a single model for performing diverse vision-language tasks effectively with simple multi-modal instructions. Towards this objective, we introduce MiniGPT-v2, a model that can be treated as a unified interface for better handling various vision-language tasks. We propose using unique identifiers for different tasks when training the model. These identifiers enable our model to better distinguish each task instruction effortlessly and also improve the model learning efficiency for each task. After the three-stage training, the experimental results show that MiniGPT-v2 achieves strong performance on many visual question-answering and visual grounding benchmarks compared to other vision-language generalist models. Our model and codes are available at https://minigpt-v2.github.io/", "url": "http://arxiv.org/abs/2310.09478", "shorttitle": "{MiniGPT}-v2", "title": "MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning", "ENTRYTYPE": "misc", "ID": "chen_minigpt-v2_2023"}}}