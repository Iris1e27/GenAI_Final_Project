{"_default": {"21": {"file": "\u5168\u6587:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\4DDRLNFS\\\\Mu\u00f1oz \u7b49 - 2022 - Augmented Reality, Virtual Reality, and Game Techn.pdf:application/pdf", "pages": "222", "year": "2022", "month": "April", "author": "Mu\u00f1oz, Eduardo Gross and Fabregat, Ramon and Bacca-Acosta, Jorge and Duque-M\u00e9ndez, N\u00e9stor and Avila-Garzon, Cecilia", "journal": "Information", "urldate": "2023-10-04", "number": "5", "language": "en", "abstract": "Ophthalmology is a medical profession with a tradition in teaching that has developed throughout history. Although ophthalmologists are generally considered to only prescribe contact lenses, and they handle more than half of eye-related enhancements, diagnoses, and treatments. The training of qualified ophthalmologists is generally carried out under the traditional settings, where there is a supervisor and a student, and training is based on the use of animal eyes or artificial eye models. These models have significant disadvantages, as they are not immersive and are extremely expensive and difficult to acquire. Therefore, technologies related to Augmented Reality (AR) and Virtual Reality (VR) are rapidly and prominently positioning themselves in the medical sector, and the field of ophthalmology is growing exponentially both in terms of the training of professionals and in the assistance and recovery of patients. At the same time, it is necessary to highlight and analyze the developments that have made use of game technologies for the teaching of ophthalmology and the results that have been obtained. This systematic review aims to investigate software and hardware applications developed exclusively for educational environments related to ophthalmology and provide an analysis of other related tools. In addition, the advantages and disadvantages, limitations, and challenges involved in the use of virtual reality, augmented reality, and game technologies in this field are also presented.", "doi": "10.3390/info13050222", "url": "https://www.mdpi.com/2078-2489/13/5/222", "issn": "2078-2489", "volume": "13", "title": "Augmented Reality, Virtual Reality, and Game Technologies in Ophthalmology Training", "ENTRYTYPE": "article", "ID": "munoz_augmented_2022"}, "23": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\Q3QULVWU\\\\Kang \u7b49 - 2023 - Large Language Models are Few-shot Testers Explor.pdf:application/pdf", "pages": "2312--2323", "year": "2023", "month": "May", "author": "Kang, Sungmin and Yoon, Juyeon and Yoo, Shin", "publisher": "IEEE", "booktitle": "2023 {IEEE}/{ACM} 45th {International} {Conference} on {Software} {Engineering} ({ICSE})", "urldate": "2023-10-26", "abstract": "Many automated test generation techniques have been developed to aid developers with writing tests. To facilitate full automation, most existing techniques aim to either increase coverage, or generate exploratory inputs. However, existing test generation techniques largely fall short of achieving more semantic objectives, such as generating tests to reproduce a given bug report. Reproducing bugs is nonetheless important, as our empirical study shows that the number of tests added in open source repositories due to issues was about 28\\% of the corresponding project test suite size. Meanwhile, due to the difficulties of transforming the expected program semantics in bug reports into test oracles, existing failure reproduction techniques tend to deal exclusively with program crashes, a small subset of all bug reports. To automate test generation from general bug reports, we propose LIBRO, a framework that uses Large Language Models (LLMs), which have been shown to be capable of performing code-related tasks. Since LLMs themselves cannot execute the target buggy code, we focus on post-processing steps that help us discern when LLMs are effective, and rank the produced tests according to their validity. Our evaluation of LIBRO shows that, on the widely studied Defects4J benchmark, LIBRO can generate failure reproducing test cases for 33\\% of all studied cases (251 out of 750), while suggesting a bug reproducing test in first place for 149 bugs. To mitigate data contamination (i.e., the possibility of the LLM simply remembering the test code either partially or in whole), we also evaluate LIBRO against 31 bug reports submitted after the collection of the LLM training data terminated: LIBRO produces bug reproducing tests for 32\\% of the studied bug reports. Overall, our results show LIBRO has the potential to significantly enhance developer efficiency by automatically generating tests from bug reports.", "doi": "10.1109/ICSE48619.2023.00194", "url": "https://ieeexplore.ieee.org/document/10172763/", "shorttitle": "Large {Language} {Models} are {Few}-shot {Testers}", "isbn": "978-1-66545-701-9", "title": "Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction", "address": "Melbourne, Australia", "ENTRYTYPE": "inproceedings", "ID": "kang_large_2023"}, "24": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\9EUMVTIK\\\\Zheng \u7b49 - 2023 - Judging LLM-as-a-Judge with MT-Bench and Chatbot A.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\5PWUSKWR\\\\2306.html:text/html", "keywords": "Computer Science - Artificial Intelligence, Computer Science - Computation and Language", "note": "arXiv:2306.05685 [cs]", "year": "2023", "month": "October", "author": "Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric P. and Zhang, Hao and Gonzalez, Joseph E. and Stoica, Ion", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm\\_judge.", "url": "http://arxiv.org/abs/2306.05685", "title": "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena", "ENTRYTYPE": "misc", "ID": "zheng_judging_2023"}, "25": {"file": "\u5168\u6587:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\ZXRY9TYM\\\\Zamfirescu-Pereira \u7b49 - 2023 - Why Johnny Can\u2019t Prompt How Non-AI Experts Try (a.pdf:application/pdf", "pages": "1--21", "year": "2023", "month": "April", "author": "Zamfirescu-Pereira, J.D. and Wong, Richmond Y. and Hartmann, Bjoern and Yang, Qian", "publisher": "ACM", "booktitle": "Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Pre-trained large language models (\u201cLLMs\u201d) like GPT-3 can engage in fuent, multi-turn instruction-taking out-of-the-box, making them attractive materials for designing natural language interactions. Using natural language to steer LLM outputs (\u201cprompting\u201d) has emerged as an important design technique potentially accessible to non-AI-experts. Crafting efective prompts can be challenging, however, and prompt-based interactions are brittle. Here, we explore whether non-AI-experts can successfully engage in \u201cend-user prompt engineering\u201d using a design probe\u2014a prototype LLM-based chatbot design tool supporting development and systematic evaluation of prompting strategies. Ultimately, our probe participants explored prompt designs opportunistically, not systematically, and struggled in ways echoing end-user programming systems and interactive machine learning systems. Expectations stemming from human-to-human instructional experiences, and a tendency to overgeneralize, were barriers to efective prompt design. These fndings have implications for non-AI-expert-facing LLM-based tool design and for improving LLM-and-prompt literacy among programmers and the public, and present opportunities for further research.", "doi": "10.1145/3544548.3581388", "url": "https://dl.acm.org/doi/10.1145/3544548.3581388", "shorttitle": "Why {Johnny} {Can}\u2019t {Prompt}", "isbn": "978-1-4503-9421-5", "title": "Why Johnny Can\u2019t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts", "address": "Hamburg Germany", "ENTRYTYPE": "inproceedings", "ID": "zamfirescu-pereira_why_2023"}, "26": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\MMDZAMGG\\\\Liu \u7b49 - 2023 - LLM+P Empowering Large Language Models with Optim.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\A4ACY26B\\\\2304.html:text/html", "keywords": "Computer Science - Artificial Intelligence, Computer Science - Robotics", "note": "arXiv:2304.11477 [cs]", "year": "2023", "month": "September", "author": "Liu, Bo and Jiang, Yuqian and Zhang, Xiaohan and Liu, Qiang and Zhang, Shiqi and Biswas, Joydeep and Stone, Peter", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Large language models (LLMs) have demonstrated remarkable zero-shot generalization abilities: state-of-the-art chatbots can provide plausible answers to many common questions that arise in daily life. However, so far, LLMs cannot reliably solve long-horizon planning problems. By contrast, classical planners, once a problem is given in a formatted way, can use efficient search algorithms to quickly identify correct, or even optimal, plans. In an effort to get the best of both worlds, this paper introduces LLM+P, the first framework that incorporates the strengths of classical planners into LLMs. LLM+P takes in a natural language description of a planning problem, then returns a correct (or optimal) plan for solving that problem in natural language. LLM+P does so by first converting the language description into a file written in the planning domain definition language (PDDL), then leveraging classical planners to quickly find a solution, and then translating the found solution back into natural language. Along with LLM+P, we define a diverse set of different benchmark problems taken from common planning scenarios. Via a comprehensive set of experiments on these benchmark problems, we find that LLM+P is able to provide optimal solutions for most problems, while LLMs fail to provide even feasible plans for most problems.{\\textbackslash}footnote\\{\\vphantom{\\}}The code and results are publicly available at https://github.com/Cranial-XIX/llm-pddl.git.", "url": "http://arxiv.org/abs/2304.11477", "shorttitle": "{LLM}+{P}", "title": "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency", "ENTRYTYPE": "misc", "ID": "liu_llmp_2023"}, "27": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\I4YCHZZE\\\\Penedo \u7b49 - 2023 - The RefinedWeb Dataset for Falcon LLM Outperformi.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\HRS7Y5BL\\\\2306.html:text/html", "keywords": "Computer Science - Artificial Intelligence, Computer Science - Computation and Language", "note": "arXiv:2306.01116 [cs]", "year": "2023", "month": "June", "author": "Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Large language models are commonly trained on a mixture of filtered web data and curated high-quality corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our RefinedWeb dataset, and 1.3/7.5B parameters language models trained on it.", "url": "http://arxiv.org/abs/2306.01116", "shorttitle": "The {RefinedWeb} {Dataset} for {Falcon} {LLM}", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only", "ENTRYTYPE": "misc", "ID": "penedo_refinedweb_2023"}, "28": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\VH69VA8I\\\\Lee \u7b49 - 2022 - CoAuthor Designing a Human-AI Collaborative Writi.pdf:application/pdf", "pages": "1--19", "year": "2022", "month": "April", "author": "Lee, Mina and Liang, Percy and Yang, Qian", "publisher": "ACM", "booktitle": "{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Large language models (LMs) offer unprecedented language generation capabilities and exciting opportunities for interaction design. However, their highly context-dependent capabilities are difficult to grasp and are often subjectively interpreted. In this paper, we argue that by curating and analyzing large interaction datasets, the HCI community can foster more incisive examinations of LMs\u2019 generative capabilities. Exemplifying this approach, we present CoAuthor, a dataset designed for revealing GPT-3\u2019s capabilities in assisting creative and argumentative writing. CoAuthor captures rich interactions between 63 writers and four instances of GPT-3 across 1445 writing sessions. We demonstrate that CoAuthor can address questions about GPT-3\u2019s language, ideation, and collaboration capabilities, and reveal its contribution as a writing \u201ccollaborator\u201d under various definitions of good collaboration. Finally, we discuss how this work may facilitate a more principled discussion around LMs\u2019 promises and pitfalls in relation to interaction design. The dataset and an interface for replaying the writing sessions are publicly available at https://coauthor.stanford.edu.", "doi": "10.1145/3491102.3502030", "url": "https://dl.acm.org/doi/10.1145/3491102.3502030", "shorttitle": "{CoAuthor}", "isbn": "978-1-4503-9157-3", "title": "CoAuthor: Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities", "address": "New Orleans LA USA", "ENTRYTYPE": "inproceedings", "ID": "lee_coauthor_2022"}, "29": {"file": "\u5168\u6587:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\HURRMUAB\\\\Singh \u7b49 - 2023 - Where to Hide a Stolen Elephant Leaps in Creative.pdf:application/pdf", "pages": "1--57", "year": "2023", "month": "October", "author": "Singh, Nikhil and Bernal, Guillermo and Savchenko, Daria and Glassman, Elena L.", "journal": "ACM Transactions on Computer-Human Interaction", "urldate": "2023-10-26", "number": "5", "language": "en", "abstract": "While developing a story, novices and published writers alike have had to look outside themselves for inspiration. Language models have recently been able to generate text fluently, producing new stochastic narratives upon request. However, effectively integrating such capabilities with human cognitive faculties and creative processes remains challenging. We propose to investigate this integration with a multimodal writing support interface that offers writing suggestions textually, visually, and aurally. We conduct an extensive study that combines elicitation of prior expectations before writing, observation and semi-structured interviews during writing, and outcome evaluations after writing. Our results illustrate the individual and situational variation in machine-in-the-loop writing approaches, suggestion acceptance, and ways the system is helpful. Centrally, we report how participants perform\nintegrative leaps\n, by which they do cognitive work to integrate suggestions of varying semantic relevance into their developing stories. We interpret these findings, offering modeling and design recommendations for future creative writing support technologies.", "doi": "10.1145/3511599", "url": "https://dl.acm.org/doi/10.1145/3511599", "shorttitle": "Where to {Hide} a {Stolen} {Elephant}", "issn": "1073-0516, 1557-7325", "volume": "30", "title": "Where to Hide a Stolen Elephant: Leaps in Creative Writing with Multimodal Machine Intelligence", "ENTRYTYPE": "article", "ID": "singh_where_2023"}, "30": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\43U93HNZ\\\\Gero \u7b49 - 2022 - Sparks Inspiration for Science Writing using Lang.pdf:application/pdf", "pages": "1002--1019", "year": "2022", "month": "June", "author": "Gero, Katy Ilonka and Liu, Vivian and Chilton, Lydia", "publisher": "ACM", "booktitle": "Designing {Interactive} {Systems} {Conference}", "urldate": "2023-10-26", "language": "en", "abstract": "Large-scale language models are rapidly improving, performing well on a wide variety of tasks with little to no customization. In this work we investigate how language models can support science writing, a challenging writing task that is both open-ended and highly constrained. We present a system for generating \u201csparks\u201d, sentences related to a scientific concept intended to inspire writers. We find that our sparks are more coherent and diverse than a competitive language model baseline, and approach a human-created gold standard. In a study with 13 PhD students writing on topics of their own selection, we find three main use cases of sparks: aiding with crafting detailed sentences, providing interesting angles to engage readers, and demonstrating common reader perspectives. We also report on the various reasons sparks were considered unhelpful, and discuss how we might improve language models as writing support tools.", "doi": "10.1145/3532106.3533533", "url": "https://dl.acm.org/doi/10.1145/3532106.3533533", "shorttitle": "Sparks", "isbn": "978-1-4503-9358-4", "title": "Sparks: Inspiration for Science Writing using Language Models", "address": "Virtual Event Australia", "ENTRYTYPE": "inproceedings", "ID": "gero_sparks_2022"}, "31": {"pages": "841--852", "year": "2022", "month": "March", "author": "Yuan, Ann and Coenen, Andy and Reif, Emily and Ippolito, Daphne", "publisher": "ACM", "booktitle": "27th {International} {Conference} on {Intelligent} {User} {Interfaces}", "urldate": "2023-10-26", "language": "en", "abstract": "The latest generation of large neural language models such as GPT-3 have achieved new levels of performance on benchmarks for language understanding and generation. These models have even demonstrated an ability to perform arbitrary tasks without explicit training. In this work, we sought to learn how people might use such models in the process of creative writing. We built Wordcraft, a text editor in which users collaborate with a generative language model to write a story. We evaluated Wordcraft with a user study in which participants wrote short stories with and without the tool. Our results show that large language models enable novel co-writing experiences. For example, the language model is able to engage in open-ended conversation about the story, respond to writers\u2019 custom requests expressed in natural language (such as \u201drewrite this text to be more Dickensian\u201d), and generate suggestions that serve to unblock writers in the creative process. Based on these results, we discuss design implications for future human-AI co-writing systems.", "doi": "10.1145/3490099.3511105", "url": "https://dl.acm.org/doi/10.1145/3490099.3511105", "shorttitle": "Wordcraft", "isbn": "978-1-4503-9144-3", "title": "Wordcraft: Story Writing With Large Language Models", "address": "Helsinki Finland", "ENTRYTYPE": "inproceedings", "ID": "yuan_wordcraft_2022"}, "32": {"pages": "1--19", "year": "2022", "month": "April", "author": "Chung, John Joon Young and Kim, Wooseok and Yoo, Kang Min and Lee, Hwaran and Adar, Eytan and Chang, Minsuk", "publisher": "ACM", "booktitle": "{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "While advanced text generation algorithms (e.g., GPT-3) have enabled writers to co-create stories with an AI, guiding the narrative remains a challenge. Existing systems often leverage simple turn-taking between the writer and the AI in story development. However, writers remain unsupported in intuitively understanding the AI\u2019s actions or steering the iterative generation. We introduce TaleBrush, a generative story ideation tool that uses line sketching interactions with a GPT-based language model for control and sensemaking of a protagonist\u2019s fortune in co-created stories. Our empirical evaluation found our pipeline reliably controls story generation while maintaining the novelty of generated sentences. In a user study with 14 participants with diverse writing experiences, we found participants successfully leveraged sketching to iteratively explore and write stories according to their intentions about the character\u2019s fortune while taking inspiration from generated stories. We conclude with a reflection on how sketching interactions can facilitate the iterative human-AI co-creation process.", "doi": "10.1145/3491102.3501819", "url": "https://dl.acm.org/doi/10.1145/3491102.3501819", "shorttitle": "{TaleBrush}", "isbn": "978-1-4503-9157-3", "title": "TaleBrush: Sketching Stories with Generative Pretrained Language Models", "address": "New Orleans LA USA", "ENTRYTYPE": "inproceedings", "ID": "chung_talebrush_2022"}, "33": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\U3XYX34U\\\\Buschek \u7b49 - 2021 - The Impact of Multiple Parallel Phrase Suggestions.pdf:application/pdf", "pages": "1--13", "year": "2021", "month": "May", "author": "Buschek, Daniel and Z\u00fcrn, Martin and Eiband, Malin", "publisher": "ACM", "booktitle": "Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "We present an in-depth analysis of the impact of multi-word suggestion choices from a neural language model on user behaviour regarding input and text composition in email writing. Our study for the first time compares different numbers of parallel suggestions, and use by native and non-native English writers, to explore a trade-off of \u201cefficiency vs ideation\u201d, emerging from recent literature. We built a text editor prototype with a neural language model (GPT-2), refined in a prestudy with 30 people. In an online study (N=156), people composed emails in four conditions (0/1/3/6 parallel suggestions). Our results reveal (1) benefits for ideation, and costs for efficiency, when suggesting multiple phrases; (2) that non-native speakers benefit more from more suggestions; and (3) further insights into behaviour patterns. We discuss implications for research, the design of interactive suggestion systems, and the vision of supporting writers with AI instead of replacing them.", "doi": "10.1145/3411764.3445372", "url": "https://dl.acm.org/doi/10.1145/3411764.3445372", "isbn": "978-1-4503-8096-6", "title": "The Impact of Multiple Parallel Phrase Suggestions on Email Input and Composition Behaviour of Native and Non-Native English Writers", "address": "Yokohama Japan", "ENTRYTYPE": "inproceedings", "ID": "buschek_impact_2021"}, "34": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\L59726KB\\\\Dang \u7b49 - 2022 - Beyond Text Generation Supporting Writers with Co.pdf:application/pdf", "pages": "1--13", "year": "2022", "month": "October", "author": "Dang, Hai and Benharrak, Karim and Lehmann, Florian and Buschek, Daniel", "publisher": "ACM", "booktitle": "Proceedings of the 35th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}", "urldate": "2023-10-26", "language": "en", "abstract": "We propose a text editor to help users plan, structure and reflect on their writing process. It provides continuously updated paragraphwise summaries as margin annotations, using automatic text summarization. Summary levels range from full text, to selected (central) sentences, down to a collection of keywords. To understand how users interact with this system during writing, we conducted two user studies (N=4 and N=8) in which people wrote analytic essays about a given topic and article. As a key finding, the summaries gave users an external perspective on their writing and helped them to revise the content and scope of their drafted paragraphs. People further used the tool to quickly gain an overview of the text and developed strategies to integrate insights from the automated summaries. More broadly, this work explores and highlights the value of designing AI tools for writers, with Natural Language Processing (NLP) capabilities that go beyond direct text generation and correction.", "doi": "10.1145/3526113.3545672", "url": "https://dl.acm.org/doi/10.1145/3526113.3545672", "shorttitle": "Beyond {Text} {Generation}", "isbn": "978-1-4503-9320-1", "title": "Beyond Text Generation: Supporting Writers with Continuous Automatic Text Summaries", "address": "Bend OR USA", "ENTRYTYPE": "inproceedings", "ID": "dang_beyond_2022"}, "35": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\33AJ83GK\\\\Wu \u7b49 - 2022 - AI Chains Transparent and Controllable Human-AI I.pdf:application/pdf", "pages": "1--22", "year": "2022", "month": "April", "author": "Wu, Tongshuang and Terry, Michael and Cai, Carrie Jun", "publisher": "ACM", "booktitle": "{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by \u201cunit-testing\u201d sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications.", "doi": "10.1145/3491102.3517582", "url": "https://dl.acm.org/doi/10.1145/3491102.3517582", "shorttitle": "{AI} {Chains}", "isbn": "978-1-4503-9157-3", "title": "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts", "address": "New Orleans LA USA", "ENTRYTYPE": "inproceedings", "ID": "wu_ai_2022"}, "36": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\KY93ED9R\\\\Goodman \u7b49 - 2022 - LaMPost Design and Evaluation of an AI-assisted E.pdf:application/pdf", "pages": "1--18", "year": "2022", "month": "October", "author": "Goodman, Steven M. and Buehler, Erin and Clary, Patrick and Coenen, Andy and Donsbach, Aaron and Horne, Tiffanie N. and Lahav, Michal and MacDonald, Robert and Michaels, Rain Breaw and Narayanan, Ajit and Pushkarna, Mahima and Riley, Joel and Santana, Alex and Shi, Lei and Sweeney, Rachel and Weaver, Phil and Yuan, Ann and Morris, Meredith Ringel", "publisher": "ACM", "booktitle": "Proceedings of the 24th {International} {ACM} {SIGACCESS} {Conference} on {Computers} and {Accessibility}", "urldate": "2023-10-26", "language": "en", "abstract": "Prior work has explored the writing challenges experienced by people with dyslexia, and the potential for new spelling, grammar, and word retrieval technologies to address these challenges. However, the capabilities for natural language generation demonstrated by the latest class of large language models (LLMs) highlight an opportunity to explore new forms of human-AI writing support tools. In this paper, we introduce LaMPost, a prototype email-writing interface that explores the potential for LLMs to power writing support tools that address the varied needs of people with dyslexia. LaMPost draws from our understanding of these needs and introduces novel AI-powered features for email-writing, including: outlining main ideas, generating a subject line, suggesting changes, rewriting a selection. We evaluated LaMPost with 19 adults with dyslexia, identifying many promising routes for further exploration (including the popularity of the \u201crewrite\u201d and \u201csubject line\u201d features), but also fnding that the current generation of LLMs may not surpass the accuracy and quality thresholds required to meet the needs of writers with dyslexia. Surprisingly, we found that participants\u2019 awareness of the AI had no efect on their perception of the system, nor on their feelings of autonomy, expression, and self-efcacy when writing emails. Our fndings yield further insight into the benefts and drawbacks of using LLMs as writing support for adults with dyslexia and provide a foundation to build upon in future research.", "doi": "10.1145/3517428.3544819", "url": "https://dl.acm.org/doi/10.1145/3517428.3544819", "shorttitle": "{LaMPost}", "isbn": "978-1-4503-9258-7", "title": "LaMPost: Design and Evaluation of an AI-assisted Email Writing Prototype for Adults with Dyslexia", "address": "Athens Greece", "ENTRYTYPE": "inproceedings", "ID": "goodman_lampost_2022"}, "37": {"pages": "1--10", "year": "2021", "month": "May", "author": "Osone, Hiroyuki and Lu, Jun-Li and Ochiai, Yoichi", "publisher": "ACM", "booktitle": "Extended {Abstracts} of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Co-creation with artificial intelligence (AI) is an upcoming trend. However, less attention has been given to the construction of systems for Japanese novelists. In this study, we built \u201cBunCho\u201d, an AI supported story co-creation system in Japanese. BunCho\u2019s AI is GPT-2 (an unsupervised multitask language model) trained using a large-scale dataset of Japanese web texts and novels. With BunCho, users can generate titles and synopses from keywords. Furthermore, we propose an interactive story co-creation AI system as a tabletop role-playing game. According to summative studies of writers (N=16) and readers (N=32), 69\\% writers enjoyed writing synopses with BunCho more than by themselves, and at least one of five common metrics were improved at objective evaluation, including creativity. In addition, 63\\% writers indicated that BunCho broadened their stories. BunCho showed paths to assist Japanese novelists in creating high-level and creative writing.", "doi": "10.1145/3411763.3450391", "url": "https://dl.acm.org/doi/10.1145/3411763.3450391", "shorttitle": "{BunCho}", "isbn": "978-1-4503-8095-9", "title": "BunCho: AI Supported Story Co-Creation via Unsupervised Multitask Learning to Increase Writers\u2019 Creativity in Japanese", "address": "Yokohama Japan", "ENTRYTYPE": "inproceedings", "ID": "osone_buncho_2021"}, "38": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\4KL2K77J\\\\Coenen \u7b49 - 2021 - Wordcraft a Human-AI Collaborative Editor for Sto.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\7F8Q57UI\\\\2107.html:text/html", "keywords": "Computer Science - Computation and Language", "note": "arXiv:2107.07430 [cs]", "year": "2021", "month": "July", "author": "Coenen, Andy and Davis, Luke and Ippolito, Daphne and Reif, Emily and Yuan, Ann", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "As neural language models grow in effectiveness, they are increasingly being applied in real-world settings. However these applications tend to be limited in the modes of interaction they support. In this extended abstract, we propose Wordcraft, an AI-assisted editor for story writing in which a writer and a dialog system collaborate to write a story. Our novel interface uses few-shot learning and the natural affordances of conversation to support a variety of interactions. Our editor provides a sandbox for writers to probe the boundaries of transformer-based language models and paves the way for future human-in-the-loop training pipelines and novel evaluation methods.", "url": "http://arxiv.org/abs/2107.07430", "shorttitle": "Wordcraft", "title": "Wordcraft: a Human-AI Collaborative Editor for Story Writing", "ENTRYTYPE": "misc", "ID": "coenen_wordcraft_2021"}, "39": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\FX3AUXSJ\\\\Liu \u7b49 - 2022 - Opal Multimodal Image Generation for News Illustr.pdf:application/pdf", "pages": "1--17", "year": "2022", "month": "October", "author": "Liu, Vivian and Qiao, Han and Chilton, Lydia", "publisher": "ACM", "booktitle": "Proceedings of the 35th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}", "urldate": "2023-10-26", "language": "en", "abstract": "Advances in multimodal AI have presented people with powerful ways to create images from text. Recent work has shown that textto-image generations are able to represent a broad range of subjects and artistic styles. However, finding the right visual language for text prompts is difficult. In this paper, we address this challenge with Opal, a system that produces text-to-image generations for news illustration. Given an article, Opal guides users through a structured search for visual concepts and provides a pipeline allowing users to generate illustrations based on an article\u2019s tone, keywords, and related artistic styles. Our evaluation shows that Opal efficiently generates diverse sets of news illustrations, visual assets, and concept ideas. Users with Opal generated two times more usable results than users without. We discuss how structured exploration can help users better understand the capabilities of human AI co-creative systems.", "doi": "10.1145/3526113.3545621", "url": "https://dl.acm.org/doi/10.1145/3526113.3545621", "shorttitle": "Opal", "isbn": "978-1-4503-9320-1", "title": "Opal: Multimodal Image Generation for News Illustration", "address": "Bend OR USA", "ENTRYTYPE": "inproceedings", "ID": "liu_opal_2022"}, "40": {"pages": "1--15", "year": "2023", "month": "April", "author": "Gero, Katy Ilonka and Long, Tao and Chilton, Lydia B", "publisher": "ACM", "booktitle": "Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Recently, large language models have made huge advances in generating coherent, creative text. While much research focuses on how users can interact with language models, less work considers the social-technical gap that this technology poses. What are the social nuances that underlie receiving support from a generative AI? In this work we ask when and why a creative writer might turn to a computer versus a peer or mentor for support. We interview 20 creative writers about their writing practice and their attitudes towards both human and computer support. We discover three elements that govern a writer\u2019s interaction with support actors: 1) what writers desire help with, 2) how writers perceive potential support actors, and 3) the values writers hold. We align our results with existing frameworks of writing cognition and creativity support, uncovering the social dynamics which modulate user responses to generative technologies.", "doi": "10.1145/3544548.3580782", "url": "https://dl.acm.org/doi/10.1145/3544548.3580782", "isbn": "978-1-4503-9421-5", "title": "Social Dynamics of AI Support in Creative Writing", "address": "Hamburg Germany", "ENTRYTYPE": "inproceedings", "ID": "gero_social_2023"}, "41": {"pages": "1--16", "year": "2023", "month": "April", "author": "Petridis, Savvas and Diakopoulos, Nicholas and Crowston, Kevin and Hansen, Mark and Henderson, Keren and Jastrzebski, Stan and Nickerson, Jeffrey V and Chilton, Lydia B", "publisher": "ACM", "booktitle": "Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "News media often leverage documents to find ideas for stories, while being critical of the frames and narratives present. Developing angles from a document such as a press release is a cognitively taxing process, in which journalists critically examine the implicit meaning of its claims. Informed by interviews with journalists, we developed AngleKindling, an interactive tool which employs the common sense reasoning of large language models to help journalists explore angles for reporting on a press release. In a study with 12 professional journalists, we show that participants found AngleKindling significantly more helpful and less mentally demanding to use for brainstorming ideas, compared to a prior journalistic angle ideation tool. AngleKindling helped journalists deeply engage with the press release and recognize angles that were useful for multiple types of stories. From our findings, we discuss how to help journalists customize and identify promising angles, and extending AngleKindling to other knowledge-work domains.", "doi": "10.1145/3544548.3580907", "url": "https://dl.acm.org/doi/10.1145/3544548.3580907", "shorttitle": "{AngleKindling}", "isbn": "978-1-4503-9421-5", "title": "AngleKindling: Supporting Journalistic Angle Ideation with Large Language Models", "address": "Hamburg Germany", "ENTRYTYPE": "inproceedings", "ID": "petridis_anglekindling_2023"}, "42": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\7HZ3F46T\\\\Wang \u7b49 - 2023 - PopBlends Strategies for Conceptual Blending with.pdf:application/pdf", "pages": "1--19", "year": "2023", "month": "April", "author": "Wang, Sitong and Petridis, Savvas and Kwon, Taeahn and Ma, Xiaojuan and Chilton, Lydia B", "publisher": "ACM", "booktitle": "Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Pop culture is an important aspect of communication. On social media people often post pop culture reference images that connect an event, product or other entity to a pop culture domain. Creating these images is a creative challenge that requires finding a conceptual connection between the users\u2019 topic and a pop culture domain. In cognitive theory, this task is called conceptual blending. We present a system called PopBlends that automatically suggests conceptual blends. The system explores three approaches that involve both traditional knowledge extraction methods and large language models. Our annotation study shows that all three methods provide connections with similar accuracy, but with very different characteristics. Our user study shows that people found twice as many blend suggestions as they did without the system, and with half the mental demand. We discuss the advantages of combining large language models with knowledge bases for supporting divergent and convergent thinking.", "doi": "10.1145/3544548.3580948", "url": "https://dl.acm.org/doi/10.1145/3544548.3580948", "shorttitle": "{PopBlends}", "isbn": "978-1-4503-9421-5", "title": "PopBlends: Strategies for Conceptual Blending with Large Language Models", "address": "Hamburg Germany", "ENTRYTYPE": "inproceedings", "ID": "wang_popblends_2023"}, "43": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\WH555RBD\\\\Dang \u7b49 - 2023 - Choice Over Control How Users Write with Large La.pdf:application/pdf", "pages": "1--17", "year": "2023", "month": "April", "author": "Dang, Hai and Goller, Sven and Lehmann, Florian and Buschek, Daniel", "publisher": "ACM", "booktitle": "Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "We propose a conceptual perspective on prompts for Large Language Models (LLMs) that distinguishes between (1) diegetic prompts (part of the narrative, e.g. \u201cOnce upon a time, I saw a fox ...\u201d), and (2) non-diegetic prompts (external, e.g. \u201cWrite about the adventures of the fox.\u201d). With this lens, we study how 129 crowd workers on Prolific write short texts with different user interfaces (1 vs 3 suggestions, with/out non-diegetic prompts; implemented with GPT-3): When the interface offered multiple suggestions and provided an option for non-diegetic prompting, participants preferred choosing from multiple suggestions over controlling them via non-diegetic prompts. When participants provided non-diegetic prompts it was to ask for inspiration, topics or facts. Single suggestions in particular were guided both with diegetic and non-diegetic information. This work informs human-AI interaction with generative models by revealing that (1) writing non-diegetic prompts requires effort, (2) people combine diegetic and non-diegetic prompting, and (3) they use their draft (i.e. diegetic information) and suggestion timing to strategically guide LLMs.", "doi": "10.1145/3544548.3580969", "url": "https://dl.acm.org/doi/10.1145/3544548.3580969", "shorttitle": "Choice {Over} {Control}", "isbn": "978-1-4503-9421-5", "title": "Choice Over Control: How Users Write with Large Language Models using Diegetic and Non-Diegetic Prompting", "address": "Hamburg Germany", "ENTRYTYPE": "inproceedings", "ID": "dang_choice_2023"}, "44": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\TYWVVGBY\\\\Long \u7b49 - 2023 - Tweetorial Hooks Generative AI Tools to Motivate .pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\UKG8FYX8\\\\2305.html:text/html", "keywords": "Computer Science - Computers and Society, Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction", "note": "arXiv:2305.12265 [cs]", "year": "2023", "month": "May", "author": "Long, Tao and Zhang, Dorothy and Li, Grace and Taraif, Batool and Menon, Samia and Smith, Kynnedy Simone and Wang, Sitong and Gero, Katy Ilonka and Chilton, Lydia B.", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Communicating science and technology is essential for the public to understand and engage in a rapidly changing world. Tweetorials are an emerging phenomenon where experts explain STEM topics on social media in creative and engaging ways. However, STEM experts struggle to write an engaging \"hook\" in the first tweet that captures the reader's attention. We propose methods to use large language models (LLMs) to help users scaffold their process of writing a relatable hook for complex scientific topics. We demonstrate that LLMs can help writers find everyday experiences that are relatable and interesting to the public, avoid jargon, and spark curiosity. Our evaluation shows that the system reduces cognitive load and helps people write better hooks. Lastly, we discuss the importance of interactivity with LLMs to preserve the correctness, effectiveness, and authenticity of the writing.", "url": "http://arxiv.org/abs/2305.12265", "shorttitle": "Tweetorial {Hooks}", "title": "Tweetorial Hooks: Generative AI Tools to Motivate Science on Social Media", "ENTRYTYPE": "misc", "ID": "long_tweetorial_2023"}, "45": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\5THFZ597\\\\Shen \u7b49 - 2023 - Beyond Summarization Designing AI Support for Rea.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\PCR42KFH\\\\2304.html:text/html", "keywords": "Computer Science - Computation and Language, Computer Science - Human-Computer Interaction", "note": "arXiv:2304.02623 [cs]", "year": "2023", "month": "April", "author": "Shen, Zejiang and August, Tal and Siangliulue, Pao and Lo, Kyle and Bragg, Jonathan and Hammerbacher, Jeff and Downey, Doug and Chang, Joseph Chee and Sontag, David", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Large language models have introduced exciting new opportunities and challenges in designing and developing new AI-assisted writing support tools. Recent work has shown that leveraging this new technology can transform writing in many scenarios such as ideation during creative writing, editing support, and summarization. However, AI-supported expository writing--including real-world tasks like scholars writing literature reviews or doctors writing progress notes--is relatively understudied. In this position paper, we argue that developing AI supports for expository writing has unique and exciting research challenges and can lead to high real-world impacts. We characterize expository writing as evidence-based and knowledge-generating: it contains summaries of external documents as well as new information or knowledge. It can be seen as the product of authors' sensemaking process over a set of source documents, and the interplay between reading, reflection, and writing opens up new opportunities for designing AI support. We sketch three components for AI support design and discuss considerations for future research.", "url": "http://arxiv.org/abs/2304.02623", "shorttitle": "Beyond {Summarization}", "title": "Beyond Summarization: Designing AI Support for Real-World Expository Writing Tasks", "ENTRYTYPE": "misc", "ID": "shen_beyond_2023"}, "46": {"pages": "1--14", "year": "2019", "month": "May", "author": "Chilton, Lydia B. and Petridis, Savvas and Agrawala, Maneesh", "publisher": "ACM", "booktitle": "Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Visual blends are an advanced graphic design technique to draw attention to a message. They combine two objects in a way that is novel and useful in conveying a message symbolically. This paper presents VisiBlends, a flexible workflow for creating visual blends that follows the iterative design process. We introduce a design pattern for blending symbols based on principles of human visual object recognition. Our workflow decomposes the process into both computational techniques and human microtasks. It allows users to collaboratively generate visual blends with steps involving brainstorming, synthesis, and iteration. An evaluation of the workflow shows that decentralized groups can generate blends in independent microtasks, co-located groups can collaboratively make visual blends for their own messages, and VisiBlends improves novices' ability to make visual blends.", "doi": "10.1145/3290605.3300402", "url": "https://dl.acm.org/doi/10.1145/3290605.3300402", "shorttitle": "{VisiBlends}", "isbn": "978-1-4503-5970-2", "title": "VisiBlends: A Flexible Workflow for Visual Blends", "address": "Glasgow Scotland Uk", "ENTRYTYPE": "inproceedings", "ID": "chilton_visiblends_2019"}, "47": {"pages": "1--5", "year": "2021", "month": "May", "author": "Atarashi, Yui", "publisher": "ACM", "booktitle": "Extended {Abstracts} of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "To show off their playing, musicians publish musical performance videos on streaming services. In order to find out typical characteristics of guitar performance videos, we carried out a quantitative survey of guitar performance videos. Then, we discuss key problems of creating effects informed by the survey. According to the discussion, authoring videos with typical effects takes a long time even for experienced users because they typically need to combine multiple video tracks (e.g., lyrics and videos shot from multiple angles) into a single track. They need to synchronize all tracks with the musical piece and set transitions between them at the right timing, aware of the musical structure. This paper presents Instrumeteor, an authoring tool for musical performance videos. First, it automatically analyzes the musical structure in the tracks to align them on a single timeline. Second, it implements typical video effects informed by the survey. In this way, our tool reduces manual work and unleashes the musicians\u2019 creativity.", "doi": "10.1145/3411763.3451521", "url": "https://dl.acm.org/doi/10.1145/3411763.3451521", "shorttitle": "Instrumeteor", "isbn": "978-1-4503-8095-9", "title": "Instrumeteor: Authoring tool for Guitar Performance Video", "address": "Yokohama Japan", "ENTRYTYPE": "inproceedings", "ID": "atarashi_instrumeteor_2021"}, "48": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\S8PXYUUJ\\\\Liu \u7b49 - 2023 - 3DALL-E Integrating Text-to-Image AI in 3D Design.pdf:application/pdf", "pages": "1955--1977", "year": "2023", "month": "July", "author": "Liu, Vivian and Vermeulen, Jo and Fitzmaurice, George and Matejka, Justin", "publisher": "ACM", "booktitle": "Proceedings of the 2023 {ACM} {Designing} {Interactive} {Systems} {Conference}", "urldate": "2023-10-26", "language": "en", "abstract": "Text-to-image AI are capable of generating novel images for inspiration, but their applications for 3D design workflows and how designers can build 3D models using AI-provided inspiration have not yet been explored. To investigate this, we integrated DALL-E, GPT-3, and CLIP within a CAD software in 3DALL-E, a plugin that generates 2D image inspiration for 3D design. 3DALL-E allows users to construct text and image prompts based on what they are modeling. In a study with 13 designers, we found that designers saw great potential in 3DALL-E within their workflows and could use text-to-image AI to produce reference images, prevent design fixation, and inspire design considerations. We elaborate on prompting patterns observed across 3D modeling tasks and provide measures of prompt complexity observed across participants. From our findings, we discuss how 3DALL-E can merge with existing generative design workflows and propose prompt bibliographies as a form of human-AI design history.", "doi": "10.1145/3563657.3596098", "url": "https://dl.acm.org/doi/10.1145/3563657.3596098", "shorttitle": "{3DALL}-{E}", "isbn": "978-1-4503-9893-0", "title": "3DALL-E: Integrating Text-to-Image AI in 3D Design Workflows", "address": "Pittsburgh PA USA", "ENTRYTYPE": "inproceedings", "ID": "liu_3dall-e_2023"}, "49": {"pages": "278--293", "year": "2023", "month": "March", "author": "Hu, Xiaozhu and Huang, Yanwen and Liu, Bo and Wu, Ruolan and Hu, Yongquan and Quigley, Aaron J and Fan, Mingming and Yu, Chun and Shi, Yuanchun", "publisher": "ACM", "booktitle": "Proceedings of the 28th {International} {Conference} on {Intelligent} {User} {Interfaces}", "urldate": "2023-10-26", "language": "en", "abstract": "This work focuses on an active topic in the HCI community, namely tutorial creation by demonstration. We present a novel tool named SmartRecorder that facilitates people, without video editing skills, creating video tutorials for smartphone interaction tasks. As automatic interaction trace extraction is a key component to tutorial generation, we seek to tackle the challenges of automatically extracting user interaction traces on smartphones from screencasts. Uniquely, with respect to prior research in this field, we combine computer vision techniques with IMU-based sensing algorithms, and the technical evaluation results show the importance of smartphone IMU data in improving system performance. With the extracted key information of each step, SmartRecorder generates instructional content initially and provides tutorial creators with a tutorial refinement editor designed based on a high recall (99.38\\%) of key steps to revise the initial instructional content. Finally, SmartRecorder generates video tutorials based on refined instructional content. The results of the user study demonstrate that SmartRecorder allows non-experts to create smartphone usage video tutorials with less time and higher satisfaction from recipients.", "doi": "10.1145/3581641.3584069", "url": "https://dl.acm.org/doi/10.1145/3581641.3584069", "shorttitle": "{SmartRecorder}", "isbn": "9798400701061", "title": "SmartRecorder: An IMU-based Video Tutorial Creation by Demonstration System for Smartphone Interaction Tasks", "address": "Sydney NSW Australia", "ENTRYTYPE": "inproceedings", "ID": "hu_smartrecorder_2023"}, "50": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\RPJ5UP54\\\\Wu \u7b49 - 2022 - AI Chains Transparent and Controllable Human-AI I.pdf:application/pdf", "pages": "1--22", "year": "2022", "month": "April", "author": "Wu, Tongshuang and Terry, Michael and Cai, Carrie Jun", "publisher": "ACM", "booktitle": "{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by \u201cunit-testing\u201d sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications.", "doi": "10.1145/3491102.3517582", "url": "https://dl.acm.org/doi/10.1145/3491102.3517582", "shorttitle": "{AI} {Chains}", "isbn": "978-1-4503-9157-3", "title": "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts", "address": "New Orleans LA USA", "ENTRYTYPE": "inproceedings", "ID": "wu_ai_2022-1"}, "51": {"pages": "623--627", "year": "2022", "month": "June", "author": "Di Fede, Giulia and Rocchesso, Davide and Dow, Steven P. and Andolina, Salvatore", "publisher": "ACM", "booktitle": "Creativity and {Cognition}", "urldate": "2023-10-26", "language": "en", "abstract": "We introduce the Idea Machine, a creativity support tool that leverages large language models (LLMs) to empower people engaged in idea generation tasks. The tool includes a number of affordances that can be used to enable various levels of automation and intelligent support. Each idea entered into the system can be expanded, rewritten, or combined with other ideas or concepts. An idea suggestion mode can also be enabled to make the system proactively suggest ideas.", "doi": "10.1145/3527927.3535197", "url": "https://dl.acm.org/doi/10.1145/3527927.3535197", "shorttitle": "The {Idea} {Machine}", "isbn": "978-1-4503-9327-0", "title": "The Idea Machine: LLM-based Expansion, Rewriting, Combination, and Suggestion of Ideas", "address": "Venice Italy", "ENTRYTYPE": "inproceedings", "ID": "di_fede_idea_2022"}, "52": {"file": "arXiv Fulltext PDF:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\YZD58QMD\\\\Zamfirescu-Pereira \u7b49 - 2023 - Conversation Regression Testing A Design Techniqu.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\4YWDEYZK\\\\2302.html:text/html", "keywords": "Computer Science - Human-Computer Interaction", "note": "arXiv:2302.03154 [cs]", "year": "2023", "month": "February", "author": "Zamfirescu-Pereira, J. D. and Hartmann, Bjoern and Yang, Qian", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Pre-trained language models (LLMs) such as GPT-3 can carry fluent, multi-turn conversations out-of-the-box, making them attractive materials for chatbot design. Further, designers can improve LLM chatbot utterances by prepending textual prompts -- instructions and examples of desired interactions -- to its inputs. However, prompt-based improvements can be brittle; designers face challenges systematically understanding how a prompt strategy might impact the unfolding of subsequent conversations across users. To address this challenge, we introduce the concept of Conversation Regression Testing. Based on sample conversations with a baseline chatbot, Conversation Regression Testing tracks how conversational errors persist or are resolved by applying different prompt strategies. We embody this technique in an interactive design tool, BotDesigner, that lets designers identify archetypal errors across multiple conversations; shows common threads of conversation using a graph visualization; and highlights the effects of prompt changes across bot design iterations. A pilot evaluation demonstrates the usefulness of both the concept of regression testing and the functionalities of BotDesigner for chatbot designers.", "url": "http://arxiv.org/abs/2302.03154", "shorttitle": "Conversation {Regression} {Testing}", "title": "Conversation Regression Testing: A Design Technique for Prototyping Generalizable Prompt Strategies for Pre-trained Language Models", "ENTRYTYPE": "misc", "ID": "zamfirescu-pereira_conversation_2023"}, "53": {"file": "\u5df2\u63d0\u4ea4\u7248\u672c:C\\:\\\\Users\\\\dell\\\\Zotero\\\\storage\\\\R94HBD7N\\\\Liu \u548c Chilton - 2022 - Design Guidelines for Prompt Engineering Text-to-I.pdf:application/pdf", "pages": "1--23", "year": "2022", "month": "April", "author": "Liu, Vivian and Chilton, Lydia B", "publisher": "ACM", "booktitle": "{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}", "urldate": "2023-10-26", "language": "en", "abstract": "Text-to-image generative models are a new and powerful way to generate visual artwork. However, the open-ended nature of text as interaction is double-edged; while users can input anything and have access to an infinite range of generations, they also must engage in brute-force trial and error with the text prompt when the result quality is poor. We conduct a study exploring what prompt keywords and model hyperparameters can help produce coherent outputs. In particular, we study prompts structured to include subject and style keywords and investigate success and failure modes of these prompts. Our evaluation of 5493 generations over the course of five experiments spans 51 abstract and concrete subjects as well as 51 abstract and figurative styles. From this evaluation, we present design guidelines that can help people produce better outcomes from text-to-image generative models.", "doi": "10.1145/3491102.3501825", "url": "https://dl.acm.org/doi/10.1145/3491102.3501825", "isbn": "978-1-4503-9157-3", "title": "Design Guidelines for Prompt Engineering Text-to-Image Generative Models", "address": "New Orleans LA USA", "ENTRYTYPE": "inproceedings", "ID": "liu_design_2022"}, "54": {"keywords": "Computer Science - Computation and Language, Computer Science - Human-Computer Interaction", "note": "arXiv:2303.03283 [cs]", "year": "2023", "month": "March", "author": "Draxler, Fiona and Werner, Anna and Lehmann, Florian and Hoppe, Matthias and Schmidt, Albrecht and Buschek, Daniel and Welsch, Robin", "publisher": "arXiv", "urldate": "2023-10-26", "abstract": "Human-AI interaction in text production increases complexity in authorship. In two empirical studies (n1 = 30 \\& n2 = 96), we investigate authorship and ownership in human-AI collaboration for personalized language generation models. We show an AI Ghostwriter Effect: Users do not consider themselves the owners and authors of AI-generated text but refrain from publicly declaring AI authorship. The degree of personalization did not impact the AI Ghostwriter Effect, and control over the model increased participants' sense of ownership. We also found that the discrepancy between the sense of ownership and the authorship declaration is stronger in interactions with a human ghostwriter and that people use similar rationalizations for authorship in AI ghostwriters and human ghostwriters. We discuss how our findings relate to psychological ownership and human-AI interaction to lay the foundations for adapting authorship frameworks and user interfaces in AI in text-generation tasks.", "url": "http://arxiv.org/abs/2303.03283", "shorttitle": "The {AI} {Ghostwriter} {Effect}", "title": "The AI Ghostwriter Effect: Users Do Not Perceive Ownership of AI-Generated Text But Self-Declare as Authors", "ENTRYTYPE": "misc", "ID": "draxler_ai_2023"}}}